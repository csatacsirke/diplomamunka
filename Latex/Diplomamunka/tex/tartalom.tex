

\DeclarePairedDelimiter{\norm}{\lVert}{\rVert}



\newcommand{\sumn}[1]{\sum\limits_{{#1}=1}^{n}}


\newcommand{\derivative}[2]{\dfrac{\partial {#1}}{\partial {#2}}}

% Ajánlott minden fő fejezetet külön fájlba írni, pl.:



%\include{tex/bevezeto}
%\include{tex/felhasznaloi}
%\include{tex/fejlesztoi}
%\include{tex/irodalom}



%A diplomamunkának a következő fő részekből kell állnia: 
%1. A dolgozatban megoldott probléma megfogalmazása.
%2. A problémakör irodalmának, az előzményeknek rövid áttekintése.
%3. A probléma megoldásának részletes ismertetése, a választott megoldás indoklása.
%4. Az eredmények összefoglaló értékelése és a levonható következtetések leírása.
%5. 5. Ha a diplomamunka fő eredménye egy program, akkor a dolgozat része a program felhasználói
%dokumentációja, fejlesztési dokumentációja

% III. A diplomamunkára vonatkozó formai követelmények:
% 1. A diplomamunkát nyomtatva, bekötve kell benyújtani az illetékes tanszékre.
% 2. A diplomamunka első oldalán fel kell tüntetni a diplomamunka címét, szerzőjének nevét,
% szakját, az illetékes tanszéket, a témavezető nevét, a külső konzulens nevét, a beadás helyét és
% a védés évét.
% 3. A dolgozat 2. oldala a hivatalos diplomamunkai témabejelentő.
% 4. A Bevezetés tartalmazzon a Diplomamunka-téma bejelentő lapon kitűzött feladat teljesítésének
% mértékére vonatkozó információt.
% 5. A diplomamunka fő részei a dolgozat önálló fejezetei legyenek.
% 6. A diplomamunkának legyen Tartalomjegyzéke és a felhasznált irodalomról Irodalomjegyzéke.
% 7. A diplomamunkában be kell tartani a hivatkozások és idézések standard szabályait. 

\section{Bevezetés}
\section{Háttér}



TODO
nyomdász
vonalvastagság
legkisebb nyomtatható elem
különböző nyomda és fénymásoló technika
akár azt is meg lehet mondani mivel készült
aktív track and trace + biztonsági elemek
-> másfeles kategóriás cuccot szeretnénk
OVD


roc


\subsection{Mikor biztonságos egy nyomat?}

Alapvetően akkor, hogy ha megpróbáljuk valahogy reprodukálni, akkor
mérhető lesz a különbség az eredeti és a hamis között.

Ha védeni szeretnénk egy dokumentumot vagy bankjegyet általában 
többféle módszert használunk egyszerre, amelyek optimális esetben 
ortogonálisak, tehát hamisításnál mindegyikre valahogy máshogyan kell 
felkészülni. Ezek a \textit{feature-öket} alapvetően két kategóriába tudjuk sorolni. 
Az első amit az utca embere is könnyen ellenőrizhet, például a Magyar Forintokon 
a fémszalag, vagy a színváltó tinta, de akár a papír taktilitása is.
A második amihez már valamilyen speciális eszköz is kell. Erre a legismertebb 
példa az UV lámpa, ami mindenhol megtalálható ahol pénz forog.
A valóságban létezik egy harmadik kategória is, ami a titkos, csak 
laborban kimutatható tulajdonságokat tartalmazza, de ezekkel érthető
módon nem foglalkozunk.


\subsection{Előző megoldások}

Ha egy nyomdász vagy szakértő ránéz egy biztonsági nyomatra, 
általában már a hagyományos, tintával készült részekből meg tudja
állapítani az eredetiséget. Ennek oka, hogy a hamisításhoz jó esetben nem áll 
rendelkezésre sem ugyanolyan papír, sem ugyanolyan nyomtató vagy olyan fénymásoló,
amely pont olyan eredményt produkál mint az eredeti.
Ennek feltétele, hogy mikor tervezzük a nyomatot tudjuk azt, hogy
milyen géppel fog készülni, és úgy tervezzük meg a nyomtatandó struktúrákat,
hogy azok éppen csak nyomtathatóak legyenek.


Kézenfekvő, hogy ezt a tudást szerették volna algoritmizálni. Így születtek olyan
programok amik ilyen képek alapján próbálják megállapítani az eredetiséget. 
Ilyenkor készítettek különböző hamisítványokat, és összehasonlították őket az eredetiekkel,
és addig csiszolták az algoritmusokat, amíg azok elfogadható eredményeket nem adtak.


Így születtek olyan megoldások, amik az első és a második fent említett kategória 
közé esnek, azaz az utca emberének lettek tervezve, de mégis céleszközt használva
ellenőrzik a nyomatot, ám ezeket egy okostelefon birtokában bárki elérheti.
Az ötlet, hogy lefényképezzük a dokumentumot, és ezt helyben, egy \textit{appal} elemezzük.


Speciálisan, az általunk részben felhasznált megoldás különböző szempontok alapján méréseket
végez a képen, és néhány (nagyságrendileg 10-12) mérőszámot ad eredményül, melyeket aztán
aggregál, és egy döntést hoz: \textit{Eredeti, Hamis, Nem tudjuk eldönteni biztonsággal}.

A \textit{Nem tudjuk} esetet több dolog is kiválthatja, például nagyon jó hamisítvány is,
de akár egy rossz kép is, például ha remegett az ember keze fényképezéskor.

\subsection{Gépi tanulás}

TODO valamit általánosan a gép tanulásról?

\subsubsection{Támasztóvektor Gép}

A Támasztóvektor Gép (Support Vector Machine, SVM) egy klaszterező eljárás, amivel egy adathalmaz két 
csoportra bontható. Alapja, hogy teret egy hipersíkkal ketté osztjuk úgy, hogy a két csoport előjeles 
távolsága ($ d_1, d_2 $) a hipersíktól maximális legyen. 
Egy csoport és sík távolsága alatt a sík és az ahhoz legközelebbi, az adott csoportba tartozó elem távolságát értjük. 


A két távolság összegét hívjuk \textit{margónak}: $ d = d_1 + d_2 $.

A bemenő adatok vektorait $ \underline{x_i} $-vel, a hozzájuk tartozó kimenetet
$ y_i $-vel, ahol $ y_i=-1 $, ha az első csoportba tartozik, és $ y_i=1 $, ha a másodikba.

A hipersíkot a normálvektorával(súlyával, weight): $ \underline{w} $, és \textit{bias}-szal 
(részlehajlás): $ b $ ábrázoljuk.


Ekkor a sík pontjai $ \underline{x}: \underline{x}^T \cdot \underline{w} - b = 0 $

A csoportok margójához tartozó hipersíkok pedig:

$ \underline{x}: \underline{x}^T \cdot \underline{w} - b = +1 $

$ \underline{x}: \underline{x}^T \cdot \underline{w} - b = -1 $
\\
Ekkor a feladat $ \underline{w} $ és $ b $ meghatározása úgy, hogy 

$ \underline{x}^T \cdot \underline{w} - b \geq +1 $ ha $  y=1 $

$ \underline{x}^T \cdot \underline{w} - b \leq -1 $ ha $  y=-1 $

Ekkor $ d_1 = d_2 = \frac{2}{\norm{\underline{w}}} $  
\\
Mivel $ d $-t szeretnénk maximalizálni, a feladat felírható:

$ y_i \cdot (\underline{x}^T \cdot \underline{w} + b) \geq 1 $

$ \min\limits_{w, b} \norm{\underline{w}} $

Ez azonban csak akkor működik, ha az adat lineárisan szeparálható. Ellenkező esetben
vezessünk be egy olyan költségfüggvényt, ami azt bünteti ami rossz oldalon van.

$ C(\underline{w},b)  = \frac{1}{n} \sum\limits_{i=1}^{n} 
max(0, 1 - y_i(\underline{w} \cdot \underline{x} - b) + \lambda \norm{\underline{w}} $



\noindent
Megmutatható, hogy a feladat megegyezik a következővel (duális probléma): 

$ \max\limits_{c_1 \dots c_n} \sum\limits_{i=1}^{n}c_i -  $
$ \frac{1}{2}\sumn{i}\sumn{j} y_i c_i (x_i \cdot x_j) y_i c_j $

\noindent
ahol $ \forall i: $

$  \sumn{i} c_i y_i = 0 $

$ 0 \leq c_i \leq \frac{1}{2n\lambda} $

\noindent
Ennek megoldására létezik hatékony numerikus módszer.

\noindent
Ekkor a súlyok:

$ \underline{w} = \sumn{i} c_i y_i x_i $

\noindent
Keressünk egy margón lévő $ (x_i, y_i) $ párt:
$ b = \underline{w}^T \cdot \underline{x}_i  - y_i$

\noindent
Egy minta osztályozása:

$ \overline{y} = sgn(\underline{w} \cdot \underline{x} - b) $

\noindent
TODO mennyire részletezzem, hogy ezt hogy kell megoldani?




\paragraph{Nem lineáris feladatok} 


Sok esetben a feladat nem lineárisan szeparálható, viszont ha a problémateret
transzformáljuk, lehet hogy már igen. 

Vezessük be a bázisfüggvényeket, amelyek az eredeti adatot egy másik térbe,
a jellemző(\textit{feature}) térbe képezik:


$ \varphi : \mathbb{R}^n \rightarrow \mathbb{R}^m $

(általában $ m >> n $ )


\noindent
Ekkor a feladat a következőképpen módosul:

$ \max\limits_{c_1 \dots c_n} \sum\limits_{i=1}^{n}c_i -  $
$ \frac{1}{2}\sumn{i}\sumn{j} y_i c_i (\varphi(x_i) \cdot \varphi(x_j)) y_i c_j $

\noindent
ahol $ \forall i: $

$  \sumn{i} c_i y_i = 0 $

$ 0 \leq c_i \leq \frac{1}{2n\lambda} $

\noindent
és ekkor

$ \underline{w} = \sumn{i} c_i y_i \varphi(x_i) $

\noindent
Keressünk egy margón lévő $ (x_i, y_i) $ párt:

$ b = \underline{w}^T \cdot \varphi(\underline{x}_i)  - y_i$


\noindent
Egy minta osztályozása ekkor:

$ \overline{y} = sgn(\underline{w} \cdot \varphi(\underline{x}) - b) $


\paragraph{Kernel trükk} 

A jellemzőtér nagy, vagy akár végtelen dimenziós is lehet. Bizonyos esetekben a fenti képletben lévő
$ \varphi(x_i) \cdot \varphi(x_j) $ skaláris szorzatot ki tudjuk számolni anélkül, hogy a transzformációt 
elvégeznénk.



\noindent
Ehhez vezessük be a \textit{kernel függvényeket}:

$ K(x_i, x_j) = \varphi(x_i)^T \cdot \varphi(x_j) $

\noindent
Látható, hogy a maximalizálás ekkor is elvégezhető, és a predikció is csak kicsit módosul
egy $ x' $ mintára:

$ y' = sgn(\underline{w} \cdot \varphi(\underline{x}) - b) = $
$ sgn(\sumn{i} c_i y_i k(\underline{x}_i, \underline{x}') - b) $



\subsubsection{Mély hálók}

Általánosságban egy mély háló egy nagy bemenetet (ez esetben képet) úgy képez
a kimenetre, hogy több kisebb lépésben tömöríti az inputot rejtett rétegek segítségével,
amíg a dimenziója el nem éri a várt kimenetét. 
(Nálunk ez egy 0 és 1 közti szám, ahol 1 az eredeti, 0 a hamis.)


Ez egy felügyelt tanulás, tehát a háló tanításához szükségünk van az inputhoz ($ \underline{x} $) 
tartozó outputra, a \textit{ground truth}ra ($ \underline{y} $). 
A háló súlyait kezdetben véletlenszerűen inicializáljuk.
Ezután minden iterációban néhány inputra lefuttatjuk a hálót, 
kapva ezzel egy kimenetet ($ \underline{y}' $).

\noindent
Nézzük ekkor a négyzetes hibát($ J $) a belső súlyok függvényében($ \underline{w} $):

$ J(\underline{w}) = \sumn{i} \norm{y_i-y_i'}_2^2 $

\noindent
Bár többféle algoritmus létezik, lényegében mindegyik ennek a hibafüggvénynek
a minimalizálására törekszik, és általában a Gradiens módszeren alapulnak.
A különbség a konvergencia sebessége és a lokális szélsőértékkel szembeni 
hibatűrő képességükben van.

Ehhez visszafelé haladva (\textit{backpropagation}) rétegenként visszaterjeszti a hibát,
és a gradienssel ellentétes irányba $ \underline{w} $-t, így csökkentve a költségfüggvény értékét.


$ \underline{w}' = \underline{w} - \gamma \cdot \triangledown J(\underline{w})$

\noindent
Ahol $ \gamma < 1 $ a tanulási együttható.


\noindent
\paragraph{Példa}
Tekintsünk egy sűrű perceptron réteget, ahol $ (x_i, y_i) $ a 
bemenet és a hozzá tartozó kimenet:

$ \underline{y}' = Relu(W \cdot \underline{x} + \underline{b}) $

$ W' = W - \gamma \cdot  \triangledown  J(\underline{W})$
$ = W - \gamma \cdot \derivative{J(W)}{W} $

$ = W - \gamma \cdot  \derivative{ \dfrac{1}{n} \sumn{i} \norm{y_i-y_i'}_2^2}{W} $


$ = W - \gamma \cdot \derivative{ \dfrac{1}{n} \sumn{i} \norm{y_i-Relu(W \cdot \underline{x}_i + \underline{b})}_2^2}{W} $

$ = W - \gamma \cdot \dfrac{1}{n} \sumn{i} 2 (y_i-Relu(W \cdot \underline{x}_i + \underline{b})) \cdot   $
$ Relu'(W \cdot \underline{x}_i + b) \cdot  diag(\underline{x}_i) $

\noindent
ahol 

$ Relu(x) =  $
$ \begin{cases}
x, & \text{ha}\ x > 0 \\
0, & \text{különben}
\end{cases} $

$ Relu'(x) =  $
$ \begin{cases}
1, & \text{ha}\ x > 0 \\
0, & \text{különben}
\end{cases} $

$ Relu(\underline{x}) = (Relu(x_1), Relu(x_2) \cdots Relu(x_n))^T $



\subsubsection{Rétegek}


Egy mély háló különböző rétegekből épülhet fel, ám a fenti deriváltakat
mindig ki lehet számolni analitikusan, ezzel növelve a robosztusságot.
Nézzük mi milyen rétegeket használunk!

\paragraph{Sűrű} (\textit{dense}) rétegről beszélünk, ha a bemenet és kimenet 
minden pontja között van kapcsolat.

\paragraph{Aktivációs} réteg például a fenti $ Relu() $ függvény, ami 
valamilyen nem-linearitást visz a modellbe, ezáltal növelve a háló 
kifejezőerejét. Ha ez nem lenne $ W_1 \cdot W_2 \cdot W_3 $ a szorzást 
elvégezve összevonható lenne egy közös $ W $ mátrixba, tehát redundáns 
lenne. Ilyen tipikus függvény még a \textit{softmax} és a \textit{sigmoid}:

$ softmax(\underline{x})_j = \dfrac{e^{x_j}}{\sumn{i}e^{x_i}} $


$ sigmoid(x) = \dfrac{e^x}{e^x + 1} $

\noindent
Az előbbit általában osztályozásnál használjuk, az utóbbit pedig 
bárhol ahol \textit{Relu}-t is használnánk, de nem akarunk végtelen 
nagy értékeket.



\paragraph{Konvolúciós réteg} Általában kétdimenziós(plusz csatornák) 
képekre használják, de létezik tetszőleges dimenziós változata. 
Matematikailag:


$ (x*k)[n] =  \sum\limits_{k=-\infty}^{\infty} x[k] \cdot k[n-k] $

$ (x*k)[n, m] =  
\sum\limits_{i=-\infty}^{\infty} 
\sum\limits_{j=-\infty}^{\infty} 
x[n, m] \cdot k[n-i, m-j] $

\noindent
Ekkor $ k $-t kernelnek hívjuk.
Ez képeknél egy $ n \times m $ dimenziós mátrix, 
ahol általában a dimenziók páratlanok, és sokszor $ n = m $ .


Konvolúciós hálóknál ilyen kereneleket rendelünk egy réteghez.
Tanításnál minden kernellel elkészítjük a kép konvolúcióját,
majd a pixelekhez tartozó eredményeket egy-egy jellemzővektorba rakjuk.
Visszaterjesztésnél ezeket az kerneleket javítjuk minden iterációban.

\noindent
Egy konvolúciós réteg alakja tehát:

$ \mathbb{R}^{w \times h \times d} \rightarrow \mathbb{R}^{w \times h \times n} $

\noindent
ahol $ w, h,d $ az előző réteg szélessége, magassága és mélysége, 
$ n $ pedig a szűrők(a jellemző-vektor elemeinek) száma.




TODO same/valid padding



\paragraph{Dekonvolúciós reteg}
A konvolúciós réteg inverze.
Autóenkódernél használjuk, mikor vissza szeretnénk állítani
a tömörített képet. Matematikailag ugyanaz mint a konvolúció,
a különbség csak az eredmény dimenziójában van.


\paragraph{Alulmintavételező réteg} (\textit{Pooling, subsampling})
Mély hálóknál az a célunk, hogy a dimenzió folyamatosan csökkenjen, erre 
jó módszer, hogy a képet feleakkorára* csökkentjük, azaz négyesével összevonjuk
a pixeleket, és valamilyen függvény segítségével kiszámoljuk belőlük az új értéket.


Legtipikusabb a maxpooling réteg, ami a négy pixel maximumát veszi.

(\textit{* Lehet n-ed részére is csökkenteni a képet, nem csak a felére})

\paragraph{Felülmintavételező réteg} (\textit{Upsampling})

Az alulmintavételezés ellentéte. Célja, hogy megtöbbszörözzük a réteg
méretét.




\subsubsection{Autóenkóder}

Az autóenkóder egy olyan speciális háló, amelynél a cél, hogy 
egy bemenetet veszteségesen egy belső reprezentációra képezünk,
majd ebből megpróbáljuk visszaállítani az eredeti inputot.
Itt nincsenek címkéink, tehát ez egy nem felügyelt tanulás.
A költségfüggvény a következőképpen alakul:


$ J(\underline{w}) = \dfrac{1}{n} \sumn{i}\norm{x_i - x_i'} $

%\noindent
%Általában $ \norm{.} $ alatt az $ L2 $ normát értjük, azaz az átlagos 
%négyzetes hibát számoljuk (\textit{Mean square error, MSE}).



\subsubsection{Költségfüggvények}

Általános alakban ha $ y $ az elvárt eredmény, és $ y' $ a háló
outputja, akkor a hibafüggvény a következő:

$ J(\underline{w}) = \dfrac{1}{n} \sumn{i} f(y, y') $


\paragraph{Átlagos négyzetes hiba} (\textit{Mean square error, MSE})


$ f(y, y') = \norm{y - y'}_2^2 $

\noindent
Az autóenkódernél ezt használjuk.


\paragraph{Keresztentrópia} (\textit{Cross-entropy})

Legyen $ y = (0, 0, \cdots 1 \cdots 0, 0)^T, $ 
ahol az 1 helye a hozzá tartozó osztály indexe.

Bináris esetben $ y=(0, 1) $ ha a mintha az egyik, és
$ y=(1, 0) $ ha a másik csoportba tartozik.

$ f(\underline{y}, \underline{y}') = - \underline{y}^T \cdot ln(\underline{y}') $

\noindent
Osztályozásnál ezt használjuk.



\subsubsection{A tanulás segítése}


\paragraph{Túltanulás} (\textit{overfitting})

Egy modell akkor jó, ha a tanító példák mellett akkor is jól működik,
ha olyan inputot kap, amilyet eddig még "nem látott". Túltanulásnak nevezzük
azt az állapotot, mikor az új adaton jelentősen romlik a teljesítmény.
Ennek több oka is lehet. Például az egyik osztályból nem kapott 
(elég) minta adatot a modell tanuláskor. Vagy ha kapott is, a minták túlságosan 
hasonlítottak egymásra, miközben a valóságban változatosabbak.


TODO 
dropout, normalizálás, balancing, augmentation
loss/accuracy - roc görbe "siker mérése"
kis kikockázás
test/val/train
early stopping


\section{Megoldási módszerek}
\subsection{Támasztóvektor gép}
\subsection{Konvolúciós háló}
\subsection{Autoencoder}
\section{Eredmények}



We did a pretty good\textsuperscript{\textit{job}}so far




