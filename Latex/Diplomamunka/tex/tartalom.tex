

\DeclarePairedDelimiter{\norm}{\lVert}{\rVert}



\newcommand{\sumn}[1]{\sum\limits_{{#1}=1}^{n}}


\newcommand{\derivative}[2]{\dfrac{\partial {#1}}{\partial {#2}}}

% Ajánlott minden fő fejezetet külön fájlba írni, pl.:



%\include{tex/bevezeto}
%\include{tex/felhasznaloi}
%\include{tex/fejlesztoi}
%\include{tex/irodalom}



%A diplomamunkának a következő fő részekből kell állnia: 
%1. A dolgozatban megoldott probléma megfogalmazása.
%2. A problémakör irodalmának, az előzményeknek rövid áttekintése.
%3. A probléma megoldásának részletes ismertetése, a választott megoldás indoklása.
%4. Az eredmények összefoglaló értékelése és a levonható következtetések leírása.
%5. 5. Ha a diplomamunka fő eredménye egy program, akkor a dolgozat része a program felhasználói
%dokumentációja, fejlesztési dokumentációja

% III. A diplomamunkára vonatkozó formai követelmények:
% 1. A diplomamunkát nyomtatva, bekötve kell benyújtani az illetékes tanszékre.
% 2. A diplomamunka első oldalán fel kell tüntetni a diplomamunka címét, szerzőjének nevét,
% szakját, az illetékes tanszéket, a témavezető nevét, a külső konzulens nevét, a beadás helyét és
% a védés évét.
% 3. A dolgozat 2. oldala a hivatalos diplomamunkai témabejelentő.
% 4. A Bevezetés tartalmazzon a Diplomamunka-téma bejelentő lapon kitűzött feladat teljesítésének
% mértékére vonatkozó információt.
% 5. A diplomamunka fő részei a dolgozat önálló fejezetei legyenek.
% 6. A diplomamunkának legyen Tartalomjegyzéke és a felhasznált irodalomról Irodalomjegyzéke.
% 7. A diplomamunkában be kell tartani a hivatkozások és idézések standard szabályait. 

\section{Bevezetés}

lorem ipsum

ide majd szöveg kerül


\newpage
\section{Háttér}



TODO
nyomdász
vonalvastagság
legkisebb nyomtatható elem
különböző nyomda és fénymásoló technika
akár azt is meg lehet mondani mivel készült
aktív track and trace + biztonsági elemek
-> másfeles kategóriás cuccot szeretnénk
OVD


roc


\subsection{Mikor biztonságos egy nyomat?}

Alapvetően akkor, hogy ha megpróbáljuk valahogy reprodukálni, akkor
mérhető lesz a különbség az eredeti és a hamis között.

Ha védeni szeretnénk egy dokumentumot vagy bankjegyet általában 
többféle módszert használunk egyszerre, amelyek optimális esetben 
ortogonálisak, tehát hamisításnál mindegyikre valahogy máshogyan kell 
felkészülni. Ezek a \textit{feature-öket} alapvetően két kategóriába tudjuk sorolni. 
Az első amit az utca embere is könnyen ellenőrizhet, például a Magyar Forintokon 
a fémszalag, vagy a színváltó tinta, de akár a papír taktilitása is.
A második amihez már valamilyen speciális eszköz is kell. Erre a legismertebb 
példa az UV lámpa, ami mindenhol megtalálható ahol pénz forog.
A valóságban létezik egy harmadik kategória is, ami a titkos, csak 
laborban kimutatható tulajdonságokat tartalmazza, de ezekkel érthető
módon nem foglalkozunk.


\subsection{Előző megoldások}

Ha egy nyomdász vagy szakértő ránéz egy biztonsági nyomatra, 
általában már a hagyományos, tintával készült részekből meg tudja
állapítani az eredetiséget. Ennek oka, hogy a hamisításhoz jó esetben nem áll 
rendelkezésre sem ugyanolyan papír, sem ugyanolyan nyomtató vagy olyan fénymásoló,
amely pont olyan eredményt produkál mint az eredeti.
Ennek feltétele, hogy mikor tervezzük a nyomatot tudjuk azt, hogy
milyen géppel fog készülni, és úgy tervezzük meg a nyomtatandó struktúrákat,
hogy azok éppen csak nyomtathatóak legyenek.


Kézenfekvő, hogy ezt a tudást szerették volna algoritmizálni. Így születtek olyan
programok amik ilyen képek alapján próbálják megállapítani az eredetiséget. 
Ilyenkor készítettek különböző hamisítványokat, és összehasonlították őket az eredetiekkel,
és addig csiszolták az algoritmusokat, amíg azok elfogadható eredményeket nem adtak.


Így születtek olyan megoldások, amik az első és a második fent említett kategória 
közé esnek, azaz az utca emberének lettek tervezve, de mégis céleszközt használva
ellenőrzik a nyomatot, ám ezeket egy okostelefon birtokában bárki elérheti.
Az ötlet, hogy lefényképezzük a dokumentumot, és ezt helyben, egy \textit{appal} elemezzük.


Speciálisan, az általunk részben felhasznált megoldás különböző szempontok alapján méréseket
végez a képen, és néhány (nagyságrendileg 10-12) mérőszámot ad eredményül, melyeket aztán
aggregál, és egy döntést hoz: \textit{Eredeti, Hamis, Nem tudjuk eldönteni bizonyosan}.

A \textit{Nem tudjuk} esetet több dolog is kiválthatja, például nagyon jó hamisítvány is,
de akár egy rossz kép is, például ha remegett az ember keze fényképezéskor.

\subsection{Gépi tanulás}

TODO valamit általánosan a gép tanulásról?

\subsubsection{Támasztóvektor Gép}

A Támasztóvektor Gép (Support Vector Machine, SVM) egy klaszterező eljárás, amivel egy adathalmaz két csoportra bontható. 

Alapja, hogy teret egy hipersíkkal ketté osztjuk úgy, hogy a két csoport előjeles távolsága ($ d_1, d_2 $) a hipersíktól maximális legyen. 
Egy csoport és sík távolsága alatt a sík és az ahhoz legközelebbi, az adott csoportba tartozó elem távolságát értjük. 


A két távolság összegét hívjuk \textit{margónak}: $ d = d_1 + d_2 $.

A bemenő adatok vektorait $ \underline{x_i} $-vel, a hozzájuk tartozó kimenetet
$ y_i $-vel, ahol $ y_i=-1 $, ha az első csoportba tartozik, és $ y_i=1 $, ha a másodikba.

A hipersíkot a normálvektorával(súlyával, weight): $ \underline{w} $, és \textit{bias}-szal 
(részlehajlás): $ b $ ábrázoljuk.


Ekkor a sík pontjai $ \underline{x}: \underline{x}^T \cdot \underline{w} - b = 0 $

A csoportok margójához tartozó hipersíkok pedig:

$ \underline{x}: \underline{x}^T \cdot \underline{w} - b = +1 $

$ \underline{x}: \underline{x}^T \cdot \underline{w} - b = -1 $
\\
Ekkor a feladat $ \underline{w} $ és $ b $ meghatározása úgy, hogy 

$ \underline{x}^T \cdot \underline{w} - b \geq +1 $ ha $  y=1 $

$ \underline{x}^T \cdot \underline{w} - b \leq -1 $ ha $  y=-1 $

Ekkor $ d_1 = d_2 = \frac{2}{\norm{\underline{w}}} $  
\\
Mivel $ d $-t szeretnénk maximalizálni, a feladat felírható:

$ y_i \cdot (\underline{x}^T \cdot \underline{w} + b) \geq 1 $

$ \min\limits_{w, b} \norm{\underline{w}} $

Ez azonban csak akkor működik, ha az adat lineárisan szeparálható. Ellenkező esetben
vezessünk be egy olyan költségfüggvényt, ami azt bünteti ami rossz oldalon van.

$ C(\underline{w},b)  = \frac{1}{n} \sum\limits_{i=1}^{n} 
max(0, 1 - y_i(\underline{w} \cdot \underline{x} - b) + \lambda \norm{\underline{w}} $



\noindent
Megmutatható, hogy a feladat megegyezik a következővel (duális probléma): 

$ \max\limits_{c_1 \dots c_n} \sum\limits_{i=1}^{n}c_i -  $
$ \frac{1}{2}\sumn{i}\sumn{j} y_i c_i (x_i \cdot x_j) y_i c_j $

\noindent
ahol $ \forall i: $

$  \sumn{i} c_i y_i = 0 $

$ 0 \leq c_i \leq \frac{1}{2n\lambda} $

\noindent
Ennek megoldására létezik hatékony numerikus módszer.

\noindent
Ekkor a súlyok:

$ \underline{w} = \sumn{i} c_i y_i x_i $

\noindent
Keressünk egy margón lévő $ (x_i, y_i) $ párt:
$ b = \underline{w}^T \cdot \underline{x}_i  - y_i$

\noindent
Egy minta osztályozása:

$ \overline{y} = sgn(\underline{w} \cdot \underline{x} - b) $

\noindent
TODO mennyire részletezzem, hogy ezt hogy kell megoldani?




\paragraph{Nem lineáris feladatok} 


Sok esetben a feladat nem lineárisan szeparálható, viszont ha a problémateret
transzformáljuk, lehet hogy már igen. 

Vezessük be a bázisfüggvényeket, amelyek az eredeti adatot egy másik térbe,
a jellemző(\textit{feature}) térbe képezik:


$ \varphi : \mathbb{R}^n \rightarrow \mathbb{R}^m $

(általában $ m >> n $ )


\noindent
Ekkor a feladat a következőképpen módosul:

$ \max\limits_{c_1 \dots c_n} \sum\limits_{i=1}^{n}c_i -  $
$ \frac{1}{2}\sumn{i}\sumn{j} y_i c_i (\varphi(x_i) \cdot \varphi(x_j)) y_i c_j $

\noindent
ahol $ \forall i: $

$  \sumn{i} c_i y_i = 0 $

$ 0 \leq c_i \leq \frac{1}{2n\lambda} $

\noindent
és ekkor

$ \underline{w} = \sumn{i} c_i y_i \varphi(x_i) $

\noindent
Keressünk egy margón lévő $ (x_i, y_i) $ párt:

$ b = \underline{w}^T \cdot \varphi(\underline{x}_i)  - y_i$


\noindent
Egy minta osztályozása ekkor:

$ \overline{y} = sgn(\underline{w} \cdot \varphi(\underline{x}) - b) $


\paragraph{Kernel trükk} 

A jellemzőtér nagy, vagy akár végtelen dimenziós is lehet. Bizonyos esetekben a fenti képletben lévő
$ \varphi(x_i) \cdot \varphi(x_j) $ skaláris szorzatot ki tudjuk számolni anélkül, hogy a transzformációt 
elvégeznénk.



\noindent
Ehhez vezessük be a \textit{kernel függvényeket}:

$ K(x_i, x_j) = \varphi(x_i)^T \cdot \varphi(x_j) $

\noindent
Látható, hogy a maximalizálás ekkor is elvégezhető, és a predikció is csak kicsit módosul
egy $ x' $ mintára:

$ y' = sgn(\underline{w} \cdot \varphi(\underline{x}) - b) = $
$ sgn(\sumn{i} c_i y_i k(\underline{x}_i, \underline{x}') - b) $


TODO mutassunk bázisfüggvényeket


\subsubsection{Mély hálók}

Általánosságban egy mély háló egy nagy bemenetet (ez esetben képet) úgy képez
a kimenetre, hogy több kisebb lépésben tömöríti az inputot rejtett rétegek segítségével,
amíg a dimenziója el nem éri a várt kimenetét. 
(Nálunk ez egy 0 és 1 közti szám, ahol 1 az eredeti, 0 a hamis.)


Ez egy felügyelt tanulás, tehát a háló tanításához szükségünk van az inputhoz ($ \underline{x} $) 
tartozó outputra, a \textit{ground truth}ra ($ \underline{y} $). 
A háló súlyait kezdetben véletlenszerűen inicializáljuk.
Ezután minden iterációban néhány inputra lefuttatjuk a hálót, 
kapva ezzel egy kimenetet ($ \underline{y}' $).

\noindent
Nézzük ekkor a négyzetes hibát($ J $) a belső súlyok függvényében($ \underline{w} $):

$ J(\underline{w}) = \sumn{i} \norm{y_i-y_i'}_2^2 $

\noindent
Bár többféle algoritmus létezik, lényegében mindegyik ennek a hibafüggvénynek
a minimalizálására törekszik, és általában a Gradiens módszeren alapulnak.
A különbség a konvergencia sebessége és a lokális szélsőértékkel szembeni 
hibatűrő képességükben van.

Ehhez visszafelé haladva (\textit{backpropagation}) rétegenként visszaterjeszti a hibát,
és a gradienssel ellentétes irányba $ \underline{w} $-t, így csökkentve a költségfüggvény értékét.


$ \underline{w}' = \underline{w} - \gamma \cdot \triangledown J(\underline{w})$

\noindent
Ahol $ \gamma < 1 $ a tanulási együttható.


\noindent
\paragraph{Példa}
Tekintsünk egy sűrű perceptron réteget, ahol $ (x_i, y_i) $ a 
bemenet és a hozzá tartozó kimenet:

$ \underline{y}' = Relu(W \cdot \underline{x} + \underline{b}) $

$ W' = W - \gamma \cdot  \triangledown  J(\underline{W})$
$ = W - \gamma \cdot \derivative{J(W)}{W} $

$ = W - \gamma \cdot  \derivative{ \dfrac{1}{n} \sumn{i} \norm{y_i-y_i'}_2^2}{W} $


$ = W - \gamma \cdot \derivative{ \dfrac{1}{n} \sumn{i} \norm{y_i-Relu(W \cdot \underline{x}_i + \underline{b})}_2^2}{W} $

$ = W - \gamma \cdot \dfrac{1}{n} \sumn{i} 2 (y_i-Relu(W \cdot \underline{x}_i + \underline{b})) \cdot   $
$ Relu'(W \cdot \underline{x}_i + b) \cdot  diag(\underline{x}_i) $


\noindent
ahol Relu - \textit{Rectified Linear Unit}:


$ Relu(x) =  $
$ \begin{cases}
x, & \text{ha}\ x > 0 \\
0, & \text{különben}
\end{cases} $

$ Relu'(x) =  $
$ \begin{cases}
1, & \text{ha}\ x > 0 \\
0, & \text{különben}
\end{cases} $

$ Relu(\underline{x}) = (Relu(x_1), Relu(x_2) \cdots Relu(x_n))^T $



\subsubsection{Rétegek}


Egy mély háló különböző rétegekből épülhet fel, ám a fenti deriváltakat
mindig ki lehet számolni analitikusan, ezzel növelve a robosztusságot.
Nézzük mi milyen rétegeket használunk!

\paragraph{Sűrű} (\textit{dense}) rétegről beszélünk, ha a bemenet és kimenet 
minden pontja között van kapcsolat.

\paragraph{Aktivációs} réteg például a fenti $ Relu() $ függvény, ami 
valamilyen nem-linearitást visz a modellbe, ezáltal növelve a háló 
kifejezőerejét. Ha ez nem lenne $ W_1 \cdot W_2 \cdot W_3 $ a szorzást 
elvégezve összevonható lenne egy közös $ W $ mátrixba, tehát redundáns 
lenne. Ilyen tipikus függvény még a \textit{softmax} és a \textit{sigmoid}:

$ softmax(\underline{x})_j = \dfrac{e^{x_j}}{\sumn{i}e^{x_i}} $


$ sigmoid(x) = \dfrac{e^x}{e^x + 1} $

\noindent
Az előbbit általában osztályozásnál használjuk, az utóbbit pedig 
bárhol ahol \textit{Relu}-t is használnánk, de nem akarunk végtelen 
nagy értékeket.



\paragraph{Konvolúciós réteg} Általában kétdimenziós(plusz csatornák) 
képekre használják, de létezik tetszőleges dimenziós változata. 
Matematikailag:


$ (x*k)[n] =  \sum\limits_{k=-\infty}^{\infty} x[k] \cdot k[n-k] $

$ (x*k)[n, m] =  
\sum\limits_{i=-\infty}^{\infty} 
\sum\limits_{j=-\infty}^{\infty} 
x[n, m] \cdot k[n-i, m-j] $

\noindent
Ekkor $ k $-t kernelnek hívjuk.
Ez képeknél egy $ n \times m $ dimenziós mátrix, 
ahol általában a dimenziók páratlanok, és sokszor $ n = m $ .


Konvolúciós hálóknál ilyen kereneleket rendelünk egy réteghez.
Tanításnál minden kernellel elkészítjük a kép konvolúcióját,
majd a pixelekhez tartozó eredményeket egy-egy jellemzővektorba rakjuk.
Visszaterjesztésnél ezeket az kerneleket javítjuk minden iterációban.

\noindent
Egy konvolúciós réteg alakja tehát:

$ \mathbb{R}^{w \times h \times d} \rightarrow \mathbb{R}^{w \times h \times n} $

\noindent
ahol $ w, h,d $ az előző réteg szélessége, magassága és mélysége, 
$ n $ pedig a szűrők(a jellemző-vektor elemeinek) száma.




TODO same/valid padding



\paragraph{Dekonvolúciós reteg}
A konvolúciós réteg inverze.
Autóenkódernél használjuk, mikor vissza szeretnénk állítani
a tömörített képet. Matematikailag ugyanaz mint a konvolúció,
a különbség csak az eredmény dimenziójában van.


\paragraph{Alulmintavételező réteg} (\textit{Pooling, subsampling})
Mély hálóknál az a célunk, hogy a dimenzió folyamatosan csökkenjen, erre 
jó módszer, hogy a képet feleakkorára* csökkentjük, azaz négyesével összevonjuk
a pixeleket, és valamilyen függvény segítségével kiszámoljuk belőlük az új értéket.


Legtipikusabb a maxpooling réteg, ami a négy pixel maximumát veszi.

(\textit{* Lehet n-ed részére is csökkenteni a képet, nem csak a felére})

\paragraph{Felülmintavételező réteg} (\textit{Upsampling})

Az alulmintavételezés ellentéte. Célja, hogy megtöbbszörözzük a réteg
méretét.




\subsubsection{Autóenkóder}

Az autóenkóder egy olyan speciális háló, amelynél a cél, hogy 
egy bemenetet veszteségesen egy belső reprezentációra képezünk,
majd ebből megpróbáljuk visszaállítani az eredeti inputot.
Itt nincsenek címkéink, tehát ez egy nem felügyelt tanulás.
A költségfüggvény a következőképpen alakul:


$ J(\underline{w}) = \dfrac{1}{n} \sumn{i}\norm{x_i - x_i'} $

%\noindent
%Általában $ \norm{.} $ alatt az $ L2 $ normát értjük, azaz az átlagos 
%négyzetes hibát számoljuk (\textit{Mean square error, MSE}).



\subsubsection{Költségfüggvények}

Általános alakban ha $ y $ az elvárt eredmény, és $ y' $ a háló
outputja, akkor a hibafüggvény a következő:

$ J(\underline{w}) = \dfrac{1}{n} \sumn{i} f(y, y') $


\paragraph{Átlagos négyzetes hiba} (\textit{Mean square error, MSE})


$ f(y, y') = \norm{y - y'}_2^2 $

\noindent
Az autóenkódernél ezt használjuk.


\paragraph{Keresztentrópia} (\textit{Cross-entropy})

Legyen $ y = (0, 0, \cdots 1 \cdots 0, 0)^T, $ 
ahol az 1 helye a hozzá tartozó osztály indexe.

Bináris esetben $ y=(0, 1) $ ha a mintha az egyik, és
$ y=(1, 0) $ ha a másik csoportba tartozik.

$ f(\underline{y}, \underline{y}') = - \underline{y}^T \cdot log(\underline{y}') $

\noindent
Osztályozásnál ezt használjuk.



\subsubsection{Kapcsolódó fogalmak}


\paragraph{Túltanulás} (\textit{overfitting})

Egy modell akkor jó, ha a tanító példák mellett akkor is jól működik,
ha olyan inputot kap, amilyet eddig még "nem látott". Túltanulásnak nevezzük
azt az állapotot, mikor az új adaton jelentősen romlik a teljesítmény.
Ennek több oka is lehet. Például az egyik osztályból nem kapott 
(elég) minta adatot a modell tanuláskor. Vagy ha kapott is, a minták túlságosan 
hasonlítottak egymásra, miközben a valóságban változatosabbak.
Ennek kiküszöbölésére lássunk  néhány módszert!


\paragraph{Hiperparaméterek}

Gépi tanulásnál megkülönböztetjük a modell belső változóit, amit 
a tanítás során az algoritmus maga állít, és a modell minden más tulajdonságát
amit a tervező ad meg. Utóbbiakat hívjuk \textit{hiperparamétereknek}.
Ide tartozik például egy kernel mérete, vagy a rétegek szerkezete.

\paragraph{Adat szeparálás}

Bevett szokás, hogy ketté osztjuk az adathalmazt, az egyik részén tanítjuk a
modellt (\textit{tanító halmaz, training set}), a másikkal ellenőrizzük, hogy mennyire teljesít jól a predikció (\textit{validációs halmaz, validation set}).

Ha csak ez a két halmazunk lenne, akkor előfordulhatna, hogy a hiperparaméterekkel
addig-addig kísérletezünk amíg egyszer csak elfogadható validációs hibát kapunk. 
Ez azonban lehet, hogy az éppen kiválasztott adat sajátossága, azaz véletlen,
ezért bevezetünk egy harmadik, a \textit{teszt halmazt}, melynek célja, hogy
mikor úgy ítéljük meg, hogy a validációs halmazzal elértük a kívánt eredményt,
ellenőrizni tudjuk, hogy valóban jól teljesítünk-e.

Ideális esetben a validációs és a teszt hiba közel megegyező.


\paragraph{Kiejtés} (\textit{dropout})
A célja, hogy a tanuló adatot szándékosan elrontsuk egy kicsit, ezáltal 
növeljük az általánosítást.
Tartozik hozzá egy valószínűségi érték, amekkora eséllyel
egy adatértéket kinullázunk mielőtt tovább adjuk a következő rétegnek.


\paragraph{Kiegyensúlyozás}
Az eredményt torzíthatja, ha a tanító adatok között
nagy a relatív elemszámkülönbség: ezt nevezzük kiegyensúlyozatlanságnak.
Ennek kiküszöbölésére az egyik módszer, hogy minden halmazból 
megpróbálunk közel egyelőre eséllyel válogatni tanításnál, vagy
amit több programcsomag is támogat, hogy az osztályoknak súlyokat adunk,
ami alapján paraméter állításnál jobban vagy kevésbé fogja
az adott algoritmus figyelembe venni az adott példát.

\paragraph{Adatgenerálás} (\textit{data augmentation})
Amennyiben nem áll rendelkezésünkre elég adat, és ez képeknél 
különösen gyakori probléma, úgy tudjuk növelni a tanító halmaz
elemszámát, hogy valós időben új adatokat generálunk a már
meglévők alapján, például egy képet affin transzformálunk,
vagy valamilyen hisztogram transzformációt alkalmazunk.


\subsubsection{A teljesítmény mérése}

Egy neuronháló tanítása általában hosszú folyamat. Valahogy meg kell
tudnunk állapítani, ha elértük a kívánt eredményt és megállhatunk,
valamint ha az optimalizálás már nem konvergál tovább, azaz elért egy 
lokális minimumot.
Ezen kívül mérni szeretnénk, hogy mennyire teljesítünk jól. 
Ezekre többféle metrika is létezik, ezek közül tekintünk néhányat.
Ezekhez vezessük be a következő bináris osztályozáshoz kapcsolódó fogalmakat:


Igaz-pozitív (\textit{true positive, tp}), 
Igaz-negatív (\textit{true negative, tn}): \\
Amikor egy példát a megfelelően osztályozunk.

Fals pozitív / Elsőfajú hiba (\textit{fp}) 
és Fals negatív / Másodfajú hiba(\textit{fn}): \\
A mi kontextusunkban az előbbi ha egy hamisítványt eredetinek
osztályozunk, a második ennek ellentéte.

Azért fontos ezek kettéválasztása, mert ez a két hiba egymás rovására 
javítható. Egy adott feladatnál preferálhatjuk, hogy melyik az elfogadhatóbb.
Egészségügyben például kisebb kárt okozhat a fals pozitív, mint egy fals negatív;
mi viszont szívesebben engedünk át egy hamisítványt, mint mondjuk  azt egy eredetire, hogy hamis.



\paragraph{ROC-görbe}
Az előző két hiba arányát a Vevő működési karakterisztika 
(\textit{Receiver operating characteristic}) 
görbével szoktuk jellemezni. A két tengelyen az egyes hibák 
rátája található, és azt mutatja meg, hogy egy adott nagyságú elsőfajú 
hiba-rátához mekkora másodfajú tartozik.



\paragraph{Pontosság} (\textit{accuracy})

Azt méri, hogy az osztályozásnál a minták hányad részben
kerültek jó osztályba.
Ha $ (y_i, y_i') $ az elvárt értékek és a hozzájuk tartozó 
predikciók, akkor

$ acc = \dfrac{\sumn{i} \chi\{y_i = y_i'\}}{n} $ 

Bár személetes, nem tükrözi igazán jól a hatékonyságot.


\paragraph{F1 score} \mbox{} 


$ F_1 = \dfrac{2tp}{2tp + fn + fp} $

\noindent
Hasonló a pontossághoz, de jobb mérőszám, ha az osztályok kiegyenlítetlenek.



\paragraph{ROC görbe alatti terület} (\textit{ROC-AUC score})

Azt mutatja mennyire jól szeparálható a két adathalmaz. 
Ha az értéke 1, akkor tökéletesen elkülönül az két eloszlás, 
minél kisebb, annál rosszabb. Ha $ \frac{1}{2} $-nél kisebb számot kapunk,
akkor gyanakodhatunk, hogy felcseréltük a két osztályt.

\paragraph{Validációs hiba} (\textit{validation loss})

A fent részletezett költségfüggvények eredménye. Ezt használjuk
tanítás közben annak mérésére, hogy a modell konvergál-e még,
és ha igen milyen sebességgel. Nem igazán személetes, végső kiértékelésnél
nem használjuk. Jó tulajdonsága, hogy nem csak azt méri, hogy jól
osztályozunk-e, hanem azt is hogy mennyire volt egyértelmű a döntés,
valamint félreosztályozásnál figyelembe veszi, hogy kicsit lőttünk-e
mellé, vagy nagyon.



\subsubsection{A tanítás menete}

Neuronháló tanításakor példákat mutatunk a modellnek, majd a kimenet
hibája alapján korrigálunk a súlyokon. Ezt a korrigálást viszont nem
minden minta után végezzük el, hanem kötegeket (\textit{mini batch}) 
készítünk, egy ilyennek az átlagos hibájával számolunk, ezáltal 
növelve a hatékonyságot és az általánosítást. Ügyelni kell azonban, hogy
akkora kötegméretet válasszunk, hogy beleférjünk a memóriába, ugyanis 
képeknél ez könnyen probléma lehet.


Bevált technika, hogy készítünk egy véletlen permutációt a tanító adatból,
és ebben a sorrendben adjuk be a példákat. Azt a ciklust, ami alatt 
az egész halmaz egyszer feldolgozásra kerül, \textit{eposz}nak hívjuk.
Eposzonként új permutációt használunk. Ezekkel biztosítjuk, hogy minden
példa azonos valószínűséggel szerepeljen.

\paragraph{Megállás}

A megállási feltétel lehet explicit, például ami alatt a validációs hibának
lennie kell. Értelemszerűen megállunk, ha a tanulási hiba már nem csökken tovább.
Azonban könnyen előfordulhat, hogy az ugyan még egyre kisebb, a validációs hiba
viszont el kezd nőni! Ilyenkor biztosak lehetünk benne, hogy a modell elkezdett
túltanulni, és ilyenkor megállunk (\textit{early-stopping}).



TODO bele lehetne írni a regularizációt



\newpage
\section{Megoldási terv}

A gépi tanulást két helyen vizsgáltuk a témakörben.
Először egy már meglévő applikáció mért eredményeit használjuk fel,
javítva a döntési folyamatot. Ehhez Támasztóvektor Gépet(SVM) használunk.
Másodszor konvolúciós hálók segítségével próbáljuk ugyanezt a döntést 
a nyers adatból, a képből meghozni. 

\subsection{Eszközök}

A megvalósítás nyelvének python-t választottunk.
A gépi tanuláshoz a \texttt{Keras} \ref{keras} és \texttt{Sklearn} \ref{sklearn} könyvtárakat 
használtuk. Ezek a \texttt{Tensorflow} \ref{tensorflow} csomag segítségével képesek a
GPU-n futni, ezáltal gyorsítva a tanítás folyamatát, ami különösképpen a 
képfeldolgozásnál volt kritikus, mert egy közepes CPU és egy erős GPU között
százszoros sebességnövekedést mértünk.

Az említett csomagok az előző fejezetben leírt módszereket használva egy
keretrendszert biztosítanak, amellyel könnyen tudunk prototípusokat készíteni,
és azonnal kipróbálni, valamint jól illeszkednek a python többi könyvtárához,
például a \texttt{numpy} (általános aritmetikai könyvtár) és \texttt{opencv} \ref{opencv}
(computer vision, képfeldolgozás).



TODO jurás cucc



\subsection{Döntéshozás SVM-mel}






TODO valahova beleirni hogy kevés mintán is tud üzemelni

TODO az svm többi paraméterét leírni
 ? és az az általánosba kell vagy ide? 



voltak random adatok
nincs szükség arra hogy tudjuk mit jelentenek a mért adatok
általános
minden projekt ilyen elveken mukodott, bármelyikre lehet alkalmazni
verdict
hasonlóan működött az eredeti algo cska kézzel volt minden megcsinálva



\subsection{Konvolúciós háló}

Ennél a megközelítésnél maguk a képek voltak a tanító adatok.
Mivel a képek érkezhetnek különböző felbontású forrásokból, célszerű volt
egyformára méreteznünk őket, ám ennél tovább mentünk, és a célzó körök koordinátái 
és az \texttt{opencv} könyvtár inverz perspektivikus transzformációja segítségével 
normalizáltuk a képeket. Végeredménynek egységesen $ 1000 \times 1000 $ pixeles képeket
választottunk.

A célzó koordináták már rendelkezésünkre álltak, de jó kutatási terület lehet ezek 
megtalálása egy erre készített neurális hálóval.


\subsubsection{A háló szerkezete}

Bár több konfigurációt kipróbáltunk, a szerkezet alapvetően mindig a következő:



\begin{enumerate} [itemsep=-1ex]
	\item Bemenet
	\item Konvolúciós + alul mintavételező rétegek
	\item Sűrű rétegek
	\item Osztályozó réteg
	\item Predikció
\end{enumerate}

A végső szerkezet Keras-sal megvalósítva:

TODO WTF az bal oldali szaggatott cucc?

\lstset{language=Python}
\begin{lstlisting}  
	model = Sequential()
	model.add(Conv2D(64, (5, 5), input_shape=input_shape))
	model.add(Activation('relu'))
	model.add(MaxPooling2D(pool_size=(2, 2)))
	
	model.add(Conv2D(64, (5, 5)))
	model.add(Activation('relu'))
	model.add(MaxPooling2D(pool_size=(2, 2)))
	
	
	model.add(Conv2D(256, (5, 5)))
	model.add(Activation('relu'))
	model.add(MaxPooling2D(pool_size=(2, 2)))
	
	model.add(Conv2D(256, (5, 5)))
	model.add(Activation('relu'))
	model.add(MaxPooling2D(pool_size=(2, 2)))
	
	
	model.add(Flatten())
	model.add(Dense(256))
	model.add(Activation('relu'))
	
	model.add(Dense(256))
	model.add(Activation('relu'))
	
	model.add(Dense(256))
	model.add(Activation('relu'))
	
	
	model.add(Dropout(0.5))
	model.add(Dense(2))
	model.add(Activation('softmax'))
	
	
	model.compile(
		loss='sparse_categorical_crossentropy',
		optimizer='adam',
		metrics=['accuracy']
	) 

\end{lstlisting}


Az $ 5 \times 5 $-ös kerneleket \textit{Relu} nemlinearitással találtuk legcélszerűbbnek,
valamint $ 2 \times 2 $ \textit{max pooling} minden réteg után.
A konvolúciós és a sűrű rétegek között egy \textit{Flatten} réteg található,
ami a $ \mathbb{R}^{w \times h \times d} $ három dimenziós mátrix formából 
$ \mathbb{R}^{w \cdot h \cdot d} $ vektort képez. Ezután további sűrű rétegek
következek \textit{Relu} nemlinearitással. Az utolsó az osztályozó
réteg, amelynek két eleme van, és a \textit{softmax} függvény segítségével kapjuk
a háló válaszát. Ez kategóriánként egy 0 és 1 közötti valós szám, ahol a kategóriák 
összege 1 (ld. softmax függvény definíció). Bár nincs közük a valószínűségszámításhoz, 
ezek a számok felfoghatók úgy, hogy mekkora eséllyel tartozik a minta az adott osztályba.
Amennyiben közelebb vagyunk nullához vagy egyhez, akkor magabiztosabb a becslés, 
$ \frac{1}{2} $ esetén bizonytalan.

Kötlségfüggvénynek \textit{keresztentrópiát} használunk. Ez végtelen nagy ha $ |y-y'|=1 $,
és 0, ha $ |y-y'|=0 $. Vegyük észre, hogy a \textit{softmax} miatt csak akkor lesz 0
a költség, ha az egyik osztály pontosan 1, a másik pedig pontosan 0.

A keresztentrópiának több változata létezik, ám ezek csak az input formájában térnek
el. Lehet például általános $ n $ elemű, bináris két elemű, vagy bináris egyváltozós.
Mi az általános esetet használtuk, de a három közül bármelyik megfelelt volna.


\subsubsection{Tanítási paraméterek}

\paragraph{Kötegméret}
Megválasztásakor arra törekedtünk, hogy minél nagyobb legyen, ezzel gyorsítva a feldolgozást.
Matematikailag is magabiztosabb a konvergencia egy határig, ha ezt növeljük, 
valamint a GPU-RAM átviteli sávszélessége ugyan nagy, de nagy a konstans késletetés, 
ami abból adódik, hogy a videókártya vezérlőszofver nem azonnal hajtja végre az adatmozgatást,
hanem csak ha elég sok összegyűlt, vagy némi idő eltelt, ezzel javítva az teljesítményt teljes 
kihasználtság esetén. Egy eposz feldolgozása akár tízszer lassabb is lehet, ha a példákat
egyesével tápláljuk be.




Megjegyzés: Talán hiba, mindenesetre létező jelenség a Tensorflow csomagban, ha GPU implementációt használunk a program kezdetekor megpróbálja a lehető legtöbb 
munkamemóriát lefoglalni magának, ami nem mindig sikerül, 
ezért előfordulhat hogy hibával elszáll a program. Erre jó workaroundnak bizonyult, hogy
korlátoztuk, hogy maximum mennyit foglalhat le. Erre szolgál a következő utasítás a kódban:
\begin{lstlisting}
	config.gpu_options.per_process_gpu_memory_fraction = 0.7
\end{lstlisting}


Felmerül a kérdés, hogy miért nem mindent a GPU-n tárolunk, ezzel megspórolva az adatmozgatást.
Sajnos körülbelül 1000 tanító képünk volt, $ 1600 \times 1600 $ felbontásban. 
Tömörítetlenül ez nem fért el a memóriában. Ezt később ugyan lecsökkentettük
$ 1000 \times 1000 $-re, így elméletben már elfért volna, de ez nem került implementálásra,
mert hosszú távon több kép esetén úgyis probléma lenne.



Találkozhatunk egy figyelmeztető üzenettel, ha elfogy a memória, ami bár nem 
okoz elszállást, de ilyenkor lassabban fut a program. Ezért érdemes úgy megválasztani
a paramétereket, hogy ez ne következzen be.


Ezek miatt a kötegeket dinamikusan töltjük be a lemezről, és adjuk át feldolgozásra.
Egy köteg mérete jelenleg 16, de ez erősebb vagy gyengébb hardver függvényében 
növelhető vagy csökkenthető. A jelenlegi modellméret és képfelbontás mellett, ez 
körülbelül a határ a tesztgépen. Ez abból adódik, hogy a Keras felépíti memóriában 
a teljes futószalagot (\textit{pipeline}), ami csak az első rétegben
$ 3 \times 1000 \times 1000 \times \times 256 $ bájt memóriát foglal.




memória warning

batchek száma, early stopping, checkpoint

tensorflow gpu 
on the fly loading - nem fér be 1000 kép
adatB méret
honnan vannak, különböző telefonok
hiányosságok
a rossz képek előszűrve vannak a pontkeresés miatt de ez még kutatásra szorul


megszopatta az offset nyomat
mekkorát vágtunk ki mert elfogyott a memória
egyentranszformáció
mennyi képünk volt
súly vs teljes modell

statisztikai mérés / külön modul

\subsection{Autoencoder}




\section{Eredmények}



\section{Konklúzió}

lehetne majd pozicionálásra is megpróbálni


\paragraph{TODO:}

kis kikockázás

batch, eposz
dropout, normalizálás, balancing, augmentation
loss/accuracy - roc görbe "siker mérése"
test/val/train
early stopping



We did a pretty good\textsuperscript{\textit{job}}so far

