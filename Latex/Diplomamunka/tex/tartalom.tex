

\DeclarePairedDelimiter{\norm}{\lVert}{\rVert}



\newcommand{\sumn}[1]{\sum\limits_{{#1}=1}^{n}}


\newcommand{\derivative}[2]{\dfrac{\partial {#1}}{\partial {#2}}}

% Ajánlott minden fő fejezetet külön fájlba írni, pl.:



%\include{tex/bevezeto}
%\include{tex/felhasznaloi}
%\include{tex/fejlesztoi}
%\include{tex/irodalom}



%A diplomamunkának a következő fő részekből kell állnia: 
%1. A dolgozatban megoldott probléma megfogalmazása.
%2. A problémakör irodalmának, az előzményeknek rövid áttekintése.
%3. A probléma megoldásának részletes ismertetése, a választott megoldás indoklása.
%4. Az eredmények összefoglaló értékelése és a levonható következtetések leírása.
%5. 5. Ha a diplomamunka fő eredménye egy program, akkor a dolgozat része a program felhasználói
%dokumentációja, fejlesztési dokumentációja

% III. A diplomamunkára vonatkozó formai követelmények:
% 1. A diplomamunkát nyomtatva, bekötve kell benyújtani az illetékes tanszékre.
% 2. A diplomamunka első oldalán fel kell tüntetni a diplomamunka címét, szerzőjének nevét,
% szakját, az illetékes tanszéket, a témavezető nevét, a külső konzulens nevét, a beadás helyét és
% a védés évét.
% 3. A dolgozat 2. oldala a hivatalos diplomamunkai témabejelentő.
% 4. A Bevezetés tartalmazzon a Diplomamunka-téma bejelentő lapon kitűzött feladat teljesítésének
% mértékére vonatkozó információt.
% 5. A diplomamunka fő részei a dolgozat önálló fejezetei legyenek.
% 6. A diplomamunkának legyen Tartalomjegyzéke és a felhasznált irodalomról Irodalomjegyzéke.
% 7. A diplomamunkában be kell tartani a hivatkozások és idézések standard szabályait. 

\section{Bevezetés}

lorem ipsum

ide majd szöveg kerül


\newpage
\section{Háttér}



TODO
nyomdász
vonalvastagság
legkisebb nyomtatható elem
különböző nyomda és fénymásoló technika
akár azt is meg lehet mondani mivel készült
aktív track and trace + biztonsági elemek
-> másfeles kategóriás cuccot szeretnénk
OVD


roc


\subsection{Mikor biztonságos egy nyomat?}

Alapvetően akkor, hogy ha megpróbáljuk valahogy reprodukálni, akkor
mérhető lesz a különbség az eredeti és a hamis között.

Ha védeni szeretnénk egy dokumentumot vagy bankjegyet általában 
többféle módszert használunk egyszerre, amelyek optimális esetben 
ortogonálisak, tehát hamisításnál mindegyikre valahogy máshogyan kell 
felkészülni. Ezek a \textit{feature-öket} alapvetően két kategóriába tudjuk sorolni. 
Az első amit az utca embere is könnyen ellenőrizhet, például a Magyar Forintokon 
a fémszalag, vagy a színváltó tinta, de akár a papír taktilitása is.
A második amihez már valamilyen speciális eszköz is kell. Erre a legismertebb 
példa az UV lámpa, ami mindenhol megtalálható ahol pénz forog.
A valóságban létezik egy harmadik kategória is, ami a titkos, csak 
laborban kimutatható tulajdonságokat tartalmazza, de ezekkel érthető
módon nem foglalkozunk.


\subsection{Előző megoldások}

Ha egy nyomdász vagy szakértő ránéz egy biztonsági nyomatra, 
általában már a hagyományos, tintával készült részekből meg tudja
állapítani az eredetiséget. Ennek oka, hogy a hamisításhoz jó esetben nem áll 
rendelkezésre sem ugyanolyan papír, sem ugyanolyan nyomtató vagy olyan fénymásoló,
amely pont olyan eredményt produkál mint az eredeti.
Ennek feltétele, hogy mikor tervezzük a nyomatot tudjuk azt, hogy
milyen géppel fog készülni, és úgy tervezzük meg a nyomtatandó struktúrákat,
hogy azok éppen csak nyomtathatóak legyenek.


Kézenfekvő, hogy ezt a tudást szerették volna algoritmizálni. Így születtek olyan
programok amik ilyen képek alapján próbálják megállapítani az eredetiséget. 
Ilyenkor készítettek különböző hamisítványokat, és összehasonlították őket az eredetiekkel,
és addig csiszolták az algoritmusokat, amíg azok elfogadható eredményeket nem adtak.


Így születtek olyan megoldások, amik az első és a második fent említett kategória 
közé esnek, azaz az utca emberének lettek tervezve, de mégis céleszközt használva
ellenőrzik a nyomatot, ám ezeket egy okostelefon birtokában bárki elérheti.
Az ötlet, hogy lefényképezzük a dokumentumot, és ezt helyben, egy \textit{appal} elemezzük.


Speciálisan, az általunk részben felhasznált megoldás különböző szempontok alapján méréseket
végez a képen, és néhány (nagyságrendileg 10-12) mérőszámot ad eredményül, melyeket aztán
aggregál, és egy döntést hoz: \textit{Eredeti, Hamis, Nem tudjuk eldönteni bizonyosan}.

A \textit{Nem tudjuk} esetet több dolog is kiválthatja, például nagyon jó hamisítvány is,
de akár egy rossz kép is, például ha remegett az ember keze fényképezéskor.

\subsection{Gépi tanulás}

TODO valamit általánosan a gép tanulásról?

\subsubsection{Támasztóvektor Gép}

A Támasztóvektor Gép (Support Vector Machine, SVM) egy klaszterező eljárás, amivel egy adathalmaz két csoportra bontható. 

Alapja, hogy teret egy hipersíkkal ketté osztjuk úgy, hogy a két csoport előjeles távolsága ($ d_1, d_2 $) a hipersíktól maximális legyen. 
Egy csoport és sík távolsága alatt a sík és az ahhoz legközelebbi, az adott csoportba tartozó elem távolságát értjük. 


A két távolság összegét hívjuk \textit{margónak}: $ d = d_1 + d_2 $.

A bemenő adatok vektorait $ \underline{x_i} $-vel, a hozzájuk tartozó kimenetet
$ y_i $-vel, ahol $ y_i=-1 $, ha az első csoportba tartozik, és $ y_i=1 $, ha a másodikba.

A hipersíkot a normálvektorával(súlyával, weight): $ \underline{w} $, és \textit{bias}-szal 
(részlehajlás): $ b $ ábrázoljuk.


Ekkor a sík pontjai $ \underline{x}: \underline{x}^T \cdot \underline{w} - b = 0 $

A csoportok margójához tartozó hipersíkok pedig:

$ \underline{x}: \underline{x}^T \cdot \underline{w} - b = +1 $

$ \underline{x}: \underline{x}^T \cdot \underline{w} - b = -1 $
\\
Ekkor a feladat $ \underline{w} $ és $ b $ meghatározása úgy, hogy 

$ \underline{x}^T \cdot \underline{w} - b \geq +1 $ ha $  y=1 $

$ \underline{x}^T \cdot \underline{w} - b \leq -1 $ ha $  y=-1 $

Ekkor $ d_1 = d_2 = \frac{2}{\norm{\underline{w}}} $  
\\
Mivel $ d $-t szeretnénk maximalizálni, a feladat felírható:

$ y_i \cdot (\underline{x}^T \cdot \underline{w} + b) \geq 1 $

$ \min\limits_{w, b} \norm{\underline{w}} $

Ez azonban csak akkor működik, ha az adat lineárisan szeparálható. Ellenkező esetben
vezessünk be egy olyan költségfüggvényt, ami azt bünteti ami rossz oldalon van.

$ C(\underline{w},b)  = \frac{1}{n} \sum\limits_{i=1}^{n} 
max(0, 1 - y_i(\underline{w} \cdot \underline{x} - b) + \lambda \norm{\underline{w}} $



\noindent
Megmutatható, hogy a feladat megegyezik a következővel (duális probléma): 

$ \max\limits_{c_1 \dots c_n} \sum\limits_{i=1}^{n}c_i -  $
$ \frac{1}{2}\sumn{i}\sumn{j} y_i c_i (x_i \cdot x_j) y_i c_j $

\noindent
ahol $ \forall i: $

$  \sumn{i} c_i y_i = 0 $

$ 0 \leq c_i \leq \frac{1}{2n\lambda} $

\noindent
Ennek megoldására létezik hatékony numerikus módszer.

\noindent
Ekkor a súlyok:

$ \underline{w} = \sumn{i} c_i y_i x_i $

\noindent
Keressünk egy margón lévő $ (x_i, y_i) $ párt:
$ b = \underline{w}^T \cdot \underline{x}_i  - y_i$

\noindent
Egy minta osztályozása:

$ \overline{y} = sgn(\underline{w} \cdot \underline{x} - b) $

\noindent
TODO mennyire részletezzem, hogy ezt hogy kell megoldani?




\paragraph{Nem lineáris feladatok} 


Sok esetben a feladat nem lineárisan szeparálható, viszont ha a problémateret
transzformáljuk, lehet hogy már igen. 

Vezessük be a bázisfüggvényeket, amelyek az eredeti adatot egy másik térbe,
a jellemző(\textit{feature}) térbe képezik:


$ \varphi : \mathbb{R}^n \rightarrow \mathbb{R}^m $

(általában $ m >> n $ )


\noindent
Ekkor a feladat a következőképpen módosul:

$ \max\limits_{c_1 \dots c_n} \sum\limits_{i=1}^{n}c_i -  $
$ \frac{1}{2}\sumn{i}\sumn{j} y_i c_i (\varphi(x_i) \cdot \varphi(x_j)) y_i c_j $

\noindent
ahol $ \forall i: $

$  \sumn{i} c_i y_i = 0 $

$ 0 \leq c_i \leq \frac{1}{2n\lambda} $

\noindent
és ekkor

$ \underline{w} = \sumn{i} c_i y_i \varphi(x_i) $

\noindent
Keressünk egy margón lévő $ (x_i, y_i) $ párt:

$ b = \underline{w}^T \cdot \varphi(\underline{x}_i)  - y_i$


\noindent
Egy minta osztályozása ekkor:

$ \overline{y} = sgn(\underline{w} \cdot \varphi(\underline{x}) - b) $


\paragraph{Kernel trükk} 

A jellemzőtér nagy, vagy akár végtelen dimenziós is lehet. Bizonyos esetekben a fenti képletben lévő
$ \varphi(x_i) \cdot \varphi(x_j) $ skaláris szorzatot ki tudjuk számolni anélkül, hogy a transzformációt 
elvégeznénk.



\noindent
Ehhez vezessük be a \textit{kernel függvényeket}:

$ K(x_i, x_j) = \varphi(x_i)^T \cdot \varphi(x_j) $

\noindent
Látható, hogy a maximalizálás ekkor is elvégezhető, és a predikció is csak kicsit módosul
egy $ x' $ mintára:

$ y' = sgn(\underline{w} \cdot \varphi(\underline{x}) - b) = $
$ sgn(\sumn{i} c_i y_i k(\underline{x}_i, \underline{x}') - b) $


TODO mutassunk bázisfüggvényeket


\subsubsection{Mély hálók}

Általánosságban egy mély háló egy nagy bemenetet (ez esetben képet) úgy képez
a kimenetre, hogy több kisebb lépésben tömöríti az inputot rejtett rétegek segítségével,
amíg a dimenziója el nem éri a várt kimenetét. 
(Nálunk ez egy 0 és 1 közti szám, ahol 1 az eredeti, 0 a hamis.)


Ez egy felügyelt tanulás, tehát a háló tanításához szükségünk van az inputhoz ($ \underline{x} $) 
tartozó outputra, a \textit{ground truth}ra ($ \underline{y} $). 
A háló súlyait kezdetben véletlenszerűen inicializáljuk.
Ezután minden iterációban néhány inputra lefuttatjuk a hálót, 
kapva ezzel egy kimenetet ($ \underline{y}' $).

\noindent
Nézzük ekkor a négyzetes hibát($ J $) a belső súlyok függvényében($ \underline{w} $):

$ J(\underline{w}) = \sumn{i} \norm{y_i-y_i'}_2^2 $

\noindent
Bár többféle algoritmus létezik, lényegében mindegyik ennek a hibafüggvénynek
a minimalizálására törekszik, és általában a Gradiens módszeren alapulnak.
A különbség a konvergencia sebessége és a lokális szélsőértékkel szembeni 
hibatűrő képességükben van.

Ehhez visszafelé haladva (\textit{backpropagation}) rétegenként visszaterjeszti a hibát,
és a gradienssel ellentétes irányba $ \underline{w} $-t, így csökkentve a költségfüggvény értékét.


$ \underline{w}' = \underline{w} - \gamma \cdot \triangledown J(\underline{w})$

\noindent
Ahol $ \gamma < 1 $ a tanulási együttható.


\noindent
\paragraph{Példa}
Tekintsünk egy sűrű perceptron réteget, ahol $ (x_i, y_i) $ a 
bemenet és a hozzá tartozó kimenet:

$ \underline{y}' = Relu(W \cdot \underline{x} + \underline{b}) $

$ W' = W - \gamma \cdot  \triangledown  J(\underline{W})$
$ = W - \gamma \cdot \derivative{J(W)}{W} $

$ = W - \gamma \cdot  \derivative{ \dfrac{1}{n} \sumn{i} \norm{y_i-y_i'}_2^2}{W} $


$ = W - \gamma \cdot \derivative{ \dfrac{1}{n} \sumn{i} \norm{y_i-Relu(W \cdot \underline{x}_i + \underline{b})}_2^2}{W} $

$ = W - \gamma \cdot \dfrac{1}{n} \sumn{i} 2 (y_i-Relu(W \cdot \underline{x}_i + \underline{b})) \cdot   $
$ Relu'(W \cdot \underline{x}_i + b) \cdot  diag(\underline{x}_i) $


\noindent
ahol Relu - \textit{Rectified Linear Unit}:


$ Relu(x) =  $
$ \begin{cases}
x, & \text{ha}\ x > 0 \\
0, & \text{különben}
\end{cases} $

$ Relu'(x) =  $
$ \begin{cases}
1, & \text{ha}\ x > 0 \\
0, & \text{különben}
\end{cases} $

$ Relu(\underline{x}) = (Relu(x_1), Relu(x_2) \cdots Relu(x_n))^T $



\subsubsection{Rétegek}


Egy mély háló különböző rétegekből épülhet fel, ám a fenti deriváltakat
mindig ki lehet számolni analitikusan, ezzel növelve a robosztusságot.
Nézzük mi milyen rétegeket használunk!

\paragraph{Sűrű} (\textit{dense}) rétegről beszélünk, ha a bemenet és kimenet 
minden pontja között van kapcsolat.

\paragraph{Aktivációs} réteg például a fenti $ Relu() $ függvény, ami 
valamilyen nem-linearitást visz a modellbe, ezáltal növelve a háló 
kifejezőerejét. Ha ez nem lenne $ W_1 \cdot W_2 \cdot W_3 $ a szorzást 
elvégezve összevonható lenne egy közös $ W $ mátrixba, tehát redundáns 
lenne. Ilyen tipikus függvény még a \textit{softmax} és a \textit{sigmoid}:

$ softmax(\underline{x})_j = \dfrac{e^{x_j}}{\sumn{i}e^{x_i}} $


$ sigmoid(x) = \dfrac{e^x}{e^x + 1} $

\noindent
Az előbbit általában osztályozásnál használjuk, az utóbbit pedig 
bárhol ahol \textit{Relu}-t is használnánk, de nem akarunk végtelen 
nagy értékeket.



\paragraph{Konvolúciós réteg} Általában kétdimenziós(plusz csatornák) 
képekre használják, de létezik tetszőleges dimenziós változata. 
Matematikailag:


$ (x*k)[n] =  \sum\limits_{k=-\infty}^{\infty} x[k] \cdot k[n-k] $

$ (x*k)[n, m] =  
\sum\limits_{i=-\infty}^{\infty} 
\sum\limits_{j=-\infty}^{\infty} 
x[n, m] \cdot k[n-i, m-j] $

\noindent
Ekkor $ k $-t kernelnek hívjuk.
Ez képeknél egy $ n \times m $ dimenziós mátrix, 
ahol általában a dimenziók páratlanok, és sokszor $ n = m $ .


Konvolúciós hálóknál ilyen kereneleket rendelünk egy réteghez.
Tanításnál minden kernellel elkészítjük a kép konvolúcióját,
majd a pixelekhez tartozó eredményeket egy-egy jellemzővektorba rakjuk.
Visszaterjesztésnél ezeket az kerneleket javítjuk minden iterációban.

\noindent
Egy konvolúciós réteg alakja tehát:

$ \mathbb{R}^{w \times h \times d} \rightarrow \mathbb{R}^{w \times h \times n} $

\noindent
ahol $ w, h,d $ az előző réteg szélessége, magassága és mélysége, 
$ n $ pedig a szűrők(a jellemző-vektor elemeinek) száma.




TODO same/valid padding



\paragraph{Dekonvolúciós reteg}
A konvolúciós réteg inverze.
Autóenkódernél használjuk, mikor vissza szeretnénk állítani
a tömörített képet. Matematikailag ugyanaz mint a konvolúció,
a különbség csak az eredmény dimenziójában van.


\paragraph{Alulmintavételező réteg} (\textit{Pooling, subsampling})
Mély hálóknál az a célunk, hogy a dimenzió folyamatosan csökkenjen, erre 
jó módszer, hogy a képet feleakkorára* csökkentjük, azaz négyesével összevonjuk
a pixeleket, és valamilyen függvény segítségével kiszámoljuk belőlük az új értéket.


Legtipikusabb a maxpooling réteg, ami a négy pixel maximumát veszi.

(\textit{* Lehet n-ed részére is csökkenteni a képet, nem csak a felére})

\paragraph{Felülmintavételező réteg} (\textit{Upsampling})

Az alulmintavételezés ellentéte. Célja, hogy megtöbbszörözzük a réteg
méretét.




\subsubsection{Autóenkóder}

Az autóenkóder egy olyan speciális háló, amelynél a cél, hogy 
egy bemenetet veszteségesen egy belső reprezentációra képezünk,
majd ebből megpróbáljuk visszaállítani az eredeti inputot.
Itt nincsenek címkéink, tehát ez egy nem felügyelt tanulás.
A költségfüggvény a következőképpen alakul:


$ J(\underline{w}) = \dfrac{1}{n} \sumn{i}\norm{x_i - x_i'} $

%\noindent
%Általában $ \norm{.} $ alatt az $ L2 $ normát értjük, azaz az átlagos 
%négyzetes hibát számoljuk (\textit{Mean square error, MSE}).



\subsubsection{Költségfüggvények}

Általános alakban ha $ y $ az elvárt eredmény, és $ y' $ a háló
outputja, akkor a hibafüggvény a következő:

$ J(\underline{w}) = \dfrac{1}{n} \sumn{i} f(y, y') $


\paragraph{Átlagos négyzetes hiba} (\textit{Mean square error, MSE})


$ f(y, y') = \norm{y - y'}_2^2 $

\noindent
Az autoencodernél ezt használjuk.


\paragraph{Keresztentrópia} (\textit{Cross-entropy})

Legyen $ y = (0, 0, \cdots 1 \cdots 0, 0)^T, $ 
ahol az 1 helye a hozzá tartozó osztály indexe.

Bináris esetben $ y=(0, 1) $ ha a mintha az egyik, és
$ y=(1, 0) $ ha a másik csoportba tartozik.

$ f(\underline{y}, \underline{y}') = - \underline{y}^T \cdot log(\underline{y}') $

\noindent
Osztályozásnál ezt használjuk.



\subsubsection{Kapcsolódó fogalmak}


\paragraph{Túltanulás} (\textit{overfitting})

Egy modell akkor jó, ha a tanító példák mellett akkor is jól működik,
ha olyan inputot kap, amilyet eddig még "nem látott". Túltanulásnak nevezzük
azt az állapotot, mikor az új adaton jelentősen romlik a teljesítmény.
Ennek több oka is lehet. Például az egyik osztályból nem kapott 
(elég) minta adatot a modell tanuláskor. Vagy ha kapott is, a minták túlságosan 
hasonlítottak egymásra, miközben a valóságban változatosabbak.
Ennek kiküszöbölésére lássunk  néhány módszert!


\paragraph{Hiperparaméterek}

Gépi tanulásnál megkülönböztetjük a modell belső változóit, amit 
a tanítás során az algoritmus maga állít, és a modell minden más tulajdonságát
amit a tervező ad meg. Utóbbiakat hívjuk \textit{hiperparamétereknek}.
Ide tartozik például egy kernel mérete, vagy a rétegek szerkezete.

\paragraph{Adat szeparálás}

Bevett szokás, hogy ketté osztjuk az adathalmazt, az egyik részén tanítjuk a
modellt (\textit{tanító halmaz, training set}), a másikkal ellenőrizzük, hogy mennyire teljesít jól a predikció (\textit{validációs halmaz, validation set}).

Ha csak ez a két halmazunk lenne, akkor előfordulhatna, hogy a hiperparaméterekkel
addig-addig kísérletezünk amíg egyszer csak elfogadható validációs hibát kapunk. 
Ez azonban lehet, hogy az éppen kiválasztott adat sajátossága, azaz véletlen,
ezért bevezetünk egy harmadik, a \textit{teszt halmazt}, melynek célja, hogy
mikor úgy ítéljük meg, hogy a validációs halmazzal elértük a kívánt eredményt,
ellenőrizni tudjuk, hogy valóban jól teljesítünk-e.

Ideális esetben a validációs és a teszt hiba közel megegyező.


\paragraph{Kiejtés} (\textit{dropout})
A célja, hogy a tanuló adatot szándékosan elrontsuk egy kicsit, ezáltal 
növeljük az általánosítást.
Tartozik hozzá egy valószínűségi érték, amekkora eséllyel
egy adatértéket kinullázunk mielőtt tovább adjuk a következő rétegnek.


\paragraph{Kiegyensúlyozás}
Az eredményt torzíthatja, ha a tanító adatok között
nagy a relatív elemszámkülönbség: ezt nevezzük kiegyensúlyozatlanságnak.
Ennek kiküszöbölésére az egyik módszer, hogy minden halmazból 
megpróbálunk közel egyelőre eséllyel válogatni tanításnál, vagy
amit több programcsomag is támogat, hogy az osztályoknak súlyokat adunk,
ami alapján paraméter állításnál jobban vagy kevésbé fogja
az adott algoritmus figyelembe venni az adott példát.

\paragraph{Adatgenerálás} (\textit{data augmentation})
Amennyiben nem áll rendelkezésünkre elég adat, és ez képeknél 
különösen gyakori probléma, úgy tudjuk növelni a tanító halmaz
elemszámát, hogy valós időben új adatokat generálunk a már
meglévők alapján, például egy képet affin transzformálunk,
vagy valamilyen hisztogram transzformációt alkalmazunk.


\subsubsection{A teljesítmény mérése}

Egy neuronháló tanítása általában hosszú folyamat. Valahogy meg kell
tudnunk állapítani, ha elértük a kívánt eredményt és megállhatunk,
valamint ha az optimalizálás már nem konvergál tovább, azaz elért egy 
lokális minimumot.
Ezen kívül mérni szeretnénk, hogy mennyire teljesítünk jól. 
Ezekre többféle metrika is létezik, ezek közül tekintünk néhányat.
Ezekhez vezessük be a következő bináris osztályozáshoz kapcsolódó fogalmakat:


Igaz-pozitív (\textit{true positive, tp}), 
Igaz-negatív (\textit{true negative, tn}): \\
Amikor egy példát a megfelelően osztályozunk.

Fals pozitív / Elsőfajú hiba (\textit{fp}) 
és Fals negatív / Másodfajú hiba(\textit{fn}): \\
A mi kontextusunkban az előbbi ha egy hamisítványt eredetinek
osztályozunk, a második ennek ellentéte.

Azért fontos ezek kettéválasztása, mert ez a két hiba egymás rovására 
javítható. Egy adott feladatnál preferálhatjuk, hogy melyik az elfogadhatóbb.
Egészségügyben például kisebb kárt okozhat a fals pozitív, mint egy fals negatív;
mi viszont szívesebben engedünk át egy hamisítványt, mint mondjuk  azt egy eredetire, hogy hamis.



\paragraph{ROC-görbe}
Az előző két hiba arányát a Vevő működési karakterisztika 
(\textit{Receiver operating characteristic}) 
görbével szoktuk jellemezni. A két tengelyen az egyes hibák 
rátája található, és azt mutatja meg, hogy egy adott nagyságú elsőfajú 
hiba-rátához mekkora másodfajú tartozik.



\paragraph{Pontosság} (\textit{accuracy})

Azt méri, hogy az osztályozásnál a minták hányad részben
kerültek jó osztályba.
Ha $ (y_i, y_i') $ az elvárt értékek és a hozzájuk tartozó 
predikciók, akkor

$ acc = \dfrac{\sumn{i} \chi\{y_i = y_i'\}}{n} $ 

Bár személetes, nem tükrözi igazán jól a hatékonyságot.


\paragraph{F1 score} \mbox{} 


$ F_1 = \dfrac{2tp}{2tp + fn + fp} $

\noindent
Hasonló a pontossághoz, de jobb mérőszám, ha az osztályok kiegyenlítetlenek.



\paragraph{ROC görbe alatti terület} (\textit{ROC-AUC score})

Azt mutatja mennyire jól szeparálható a két adathalmaz. 
Ha az értéke 1, akkor tökéletesen elkülönül az két eloszlás, 
minél kisebb, annál rosszabb. Ha $ \frac{1}{2} $-nél kisebb számot kapunk,
akkor gyanakodhatunk, hogy felcseréltük a két osztályt.

\paragraph{Validációs hiba} (\textit{validation loss})

A fent részletezett költségfüggvények eredménye. Ezt használjuk
tanítás közben annak mérésére, hogy a modell konvergál-e még,
és ha igen milyen sebességgel. Nem igazán személetes, végső kiértékelésnél
nem használjuk. Jó tulajdonsága, hogy nem csak azt méri, hogy jól
osztályozunk-e, hanem azt is hogy mennyire volt egyértelmű a döntés,
valamint félreosztályozásnál figyelembe veszi, hogy kicsit lőttünk-e
mellé, vagy nagyon.



\subsubsection{A tanítás menete}

Neuronháló tanításakor példákat mutatunk a modellnek, majd a kimenet
hibája alapján korrigálunk a súlyokon. Ezt a korrigálást viszont nem
minden minta után végezzük el, hanem kötegeket (\textit{mini batch}) 
készítünk, egy ilyennek az átlagos hibájával számolunk, ezáltal 
növelve a hatékonyságot és az általánosítást. Ügyelni kell azonban, hogy
akkora kötegméretet válasszunk, hogy beleférjünk a memóriába, ugyanis 
képeknél ez könnyen probléma lehet.


Bevált technika, hogy készítünk egy véletlen permutációt a tanító adatból,
és ebben a sorrendben adjuk be a példákat. Azt a ciklust, ami alatt 
az egész halmaz egyszer feldolgozásra kerül, \textit{eposz}nak hívjuk.
Eposzonként új permutációt használunk. Ezekkel biztosítjuk, hogy minden
példa azonos valószínűséggel szerepeljen.

\paragraph{Megállás}

A megállási feltétel lehet explicit, például ami alatt a validációs hibának
lennie kell. Értelemszerűen megállunk, ha a tanulási hiba már nem csökken tovább.
Azonban könnyen előfordulhat, hogy az ugyan még egyre kisebb, a validációs hiba
viszont el kezd nőni! Ilyenkor biztosak lehetünk benne, hogy a modell elkezdett
túltanulni, és ilyenkor megállunk (\textit{early-stopping}).



TODO bele lehetne írni a regularizációt









% TODO lehet hogy egészségesebb lenne külön fájlba a fejezeteket

\newpage
\section{Megvalósítás}

A gépi tanulást két helyen vizsgáltuk a témakörben.
Először egy már meglévő applikáció mért eredményeit használjuk fel,
javítva a döntési folyamatot. Ehhez Támasztóvektor Gépet(SVM) használunk.
Másodszor konvolúciós hálók segítségével próbáljuk ugyanezt a döntést 
a nyers adatból, a képből meghozni. 

\subsection{Eszközök}

A megvalósítás nyelvének python-t választottunk.
A gépi tanuláshoz a \texttt{Keras} \ref{keras} és \texttt{Sklearn} \ref{sklearn} könyvtárakat 
használtuk. Ezek a \texttt{Tensorflow} \ref{tensorflow} csomag segítségével képesek a
GPU-n futni, ezáltal gyorsítva a tanítás folyamatát, ami különösképpen a 
képfeldolgozásnál volt kritikus, mert egy közepes CPU és egy erős GPU között
százszoros sebességnövekedést mértünk.

Az említett csomagok az előző fejezetben leírt módszereket használva egy
keretrendszert biztosítanak, amellyel könnyen tudunk prototípusokat készíteni,
és azonnal kipróbálni, valamint jól illeszkednek a python többi könyvtárához,
például a \texttt{numpy} (általános aritmetikai könyvtár) és \texttt{opencv} \ref{opencv}
(computer vision, képfeldolgozás).



TODO néhány szó hogy mi kell még a gpu futtatáshoz : cuda, nvidia neuronos izé


TODO jurás cucc



\subsection{Döntéshozás SVM-mel}

Az alapvető ötlet az volt, hogy vigyünk gépi tanulást egy már meglévő projektbe,
és nézzük meg, hogy ezzel tudunk-e javítani rajta. Ez a meglévő projekt, bár több 
alkalmazás készült egy-egy ipari megoldáshoz, lényegében egy képet elemez 
különböző szempontok szerint, ebből fix darab számszerű jellemzőt készít, 
majd ezek alapján döntést hoz. Ez az algoritmus minden alprojekthez egyesével
volt kézzel megírva a szakértői tapasztalatok alapján. 

Ezt a mechanizmust szerettük volna automatizálni. Abban reménykedünk, hogy egy 
mesterséges intelligencia esetleg olyan összefüggéseket is felismerhet a jellemzők
között, ami felett az ember esetleg elsiklik, valamint ha csak küszöbválasztásra
gondolunk egy elemi döntésnél biztonságosabbnak tűnik azt automatikusan, statisztikai
alapokon beállítani, mint kézzel kikísérletezni, hogy az adott példákra mikor működik jól.
További előny, hogy ha akár ugyanabba a projektbe új minta érkezik, gondoljunk akár újféle 
hamisítványra, akkor az újratanítást automatikusan el lehet végezni az új adathalmazon,
nem kell hozzá új algoritmust kitalálni. Amennyiben folyamatosan nő az adathalmazunk, 
bizonyos időközönként akár automatikusan is tudunk új szoftververziót készíteni,
ami jobban illeszkedik az új mintákhoz, és biztonságosabban ítél.


A jellemző adatokra fekete dobozként tekintettük, semmilyen formában nem használtuk fel
a jelentésüket, hagytuk hogy a gép magától találjon összefüggéseket.


Építhettünk volna egy neurális hálót is, de sokkal egyszerűbb és hatékony
megoldásnak bizonyult az SVM, amely kiváló ilyen bináris adat-klaszterezésekre.
További előnye, hogy viszonylag kevés mintán is jól és gyorsan tud tanulni.
Mindezek mellett kevesebb a hiperparamétere.


\subsubsection{Adatok}

Az adatainkat egy \texttt{csv} fájlból olvassuk ki, amit ez előzőekben említett program 
generált. Egy-egy sor tartalmazza az adott fájl elérési útját, a \textit{ground truth}-t,
a Jurás program predikcióját, néhány metaadatot, és végül a számunkra érdekes jellemzőket.
Körülbelül 1000 mintánk állt rendelkezésre.

Esetlegesen tartalmazhat egy sor egy hibaüzenetet, ha a képet nem sikerült elemezni, például 
ha annyira homályos, hogy célzóköröket nem sikerült megtalálni. Az ilyen sorokat figyelmen kívül hagyjuk.

Tekintve, hogy a tanítás időtartama alatt nem változnak az adatok, a kézzel adjuk
meg a jellemzők oszlopindexeit. A kódban ez:
\begin{lstlisting}  
	valueableParamIndices = [18, 20, 22, 24, 26, 27, 29, 30, 32, 33, 35, 36, 38, 39, 41, 42]
\end{lstlisting}

Ezeket a rekordokat kigyűjtöttük egy $ x $ tömbbe, az elvárt eredményeket egy $ y $-ba:
ezek lesznek a modellünk paraméterei.



\subsubsection{A modell}

Az SVN-ünket az \texttt{Sklearn} csomag segítségével építjük fel. 


\begin{lstlisting}  


	clf = SVC(
			C=1., 
			cache_size=200, 
			class_weight=class_weight, 
			coef0=0.0,
			decision_function_shape=None, 
			degree=2, 
			gamma='auto', 
			kernel='rbf',
			max_iter=-1,
			probability=True, 
			random_state=None, 
			shrinking=True,
			tol=0.001, 
			verbose=False)

\end{lstlisting}





négyzetes tanítási idő, nem működik 100k példára
TODO valahova beleirni hogy kevés mintán is tud üzemelni

TODO az svm többi paraméterét leírni
 ? és az az általánosba kell vagy ide? 



voltak random adatok
nincs szükség arra hogy tudjuk mit jelentenek a mért adatok
általános
minden projekt ilyen elveken mukodott, bármelyikre lehet alkalmazni
verdict
hasonlóan működött az eredeti algo cska kézzel volt minden megcsinálva



\subsection{Képelemzés Konvolúciós Hálóval}

Ennél a megközelítésnél maguk a képek voltak a tanító adatok.
Mivel a képek érkezhetnek különböző felbontású forrásokból, célszerű volt
egyformára méreteznünk őket, ám ennél tovább mentünk, és a célzó körök koordinátái 
és az \texttt{opencv} könyvtár inverz perspektivikus transzformációja segítségével 
normalizáltuk a képeket. Végeredménynek egységesen $ 1000 \times 1000 $ pixeles képeket
választottunk.

A célzó koordináták már rendelkezésünkre álltak, de jó kutatási terület lehet ezek 
megtalálása egy erre készített neurális hálóval.


Összességében azt várjuk, hogy a háló az eredeti és a hamis képeken más-más 
jellemzőket talál és tanul meg a konvolúciós szűrők segítségével, és ezeket
a \textit{feature-öket} a sűrű háló már könnyen kategorizálni tudja.

Ahogy azt a mély hálóknál szokás, a rétegek fokozatosan csökkentik a probléma
dimenzióját (kezdetben a teljes kép), amíg el nem érjük a keresett választ, 0 vagy 1 - 
egy dimenzió.

\subsubsection{A háló szerkezete}

Bár több konfigurációt kipróbáltunk, a szerkezet alapvetően mindig a következő:



\begin{enumerate} [itemsep=-1ex]
	\item Bemenet
	\item Konvolúciós + alul mintavételező rétegek
	\item Sűrű rétegek
	\item Osztályozó réteg
	\item Predikció
\end{enumerate}

A végső szerkezet Keras segítségével megvalósítva:

TODO WTF az bal oldali szaggatott cucc?

\lstset{language=Python}
\begin{lstlisting}  
	model = Sequential()
	model.add(Conv2D(64, (5, 5), input_shape=input_shape))
	model.add(Activation('relu'))
	model.add(MaxPooling2D(pool_size=(2, 2)))
	
	model.add(Conv2D(64, (5, 5)))
	model.add(Activation('relu'))
	model.add(MaxPooling2D(pool_size=(2, 2)))
	
	
	model.add(Conv2D(256, (5, 5)))
	model.add(Activation('relu'))
	model.add(MaxPooling2D(pool_size=(2, 2)))
	
	model.add(Conv2D(256, (5, 5)))
	model.add(Activation('relu'))
	model.add(MaxPooling2D(pool_size=(2, 2)))
	
	
	model.add(Flatten())
	model.add(Dense(256))
	model.add(Activation('relu'))
	
	model.add(Dense(256))
	model.add(Activation('relu'))
	
	model.add(Dense(256))
	model.add(Activation('relu'))
	
	
	model.add(Dropout(0.5))
	model.add(Dense(2))
	model.add(Activation('softmax'))
	
	
	model.compile(
		loss='sparse_categorical_crossentropy',
		optimizer='adam',
		metrics=['accuracy']
	) 

\end{lstlisting}


Az $ 5 \times 5 $-ös kerneleket \textit{Relu} nemlinearitással találtuk legcélszerűbbnek,
valamint $ 2 \times 2 $ \textit{max pooling} minden réteg után.
A konvolúciós és a sűrű rétegek között egy \textit{Flatten} réteg található,
ami a $ \mathbb{R}^{w \times h \times d} $ három dimenziós mátrix formából 
$ \mathbb{R}^{w \cdot h \cdot d} $ vektort képez. Ezután további sűrű rétegek
következek \textit{Relu} nemlinearitással. Az utolsó az osztályozó
réteg, amelynek két eleme van, és a \textit{softmax} függvény segítségével kapjuk
a háló válaszát. Ez kategóriánként egy 0 és 1 közötti valós szám, ahol a kategóriák 
összege 1 (ld. softmax függvény definíció). Bár nincs közük a valószínűségszámításhoz, 
ezek a számok felfoghatók úgy, hogy mekkora eséllyel tartozik a minta az adott osztályba.
Amennyiben közelebb vagyunk nullához vagy egyhez, akkor magabiztosabb a becslés, 
$ \frac{1}{2} $ esetén bizonytalan.

Kötlségfüggvénynek \textit{keresztentrópiát} használunk. Ez végtelen nagy ha $ |y-y'|=1 $,
és 0, ha $ |y-y'|=0 $. Vegyük észre, hogy a \textit{softmax} miatt csak akkor lesz 0
a költség, ha az egyik osztály pontosan 1, a másik pedig pontosan 0.

A keresztentrópiának több változata létezik, ám ezek csak az input formájában térnek
el. Lehet például általános $ n $ elemű, bináris két elemű, vagy bináris egyváltozós.
Mi az általános esetet használtuk, de a három közül bármelyik megfelelt volna.


\subsubsection{Tanítási paraméterek}

\paragraph{Kötegméret}
Megválasztásakor arra törekedtünk, hogy minél nagyobb legyen, ezzel gyorsítva a feldolgozást.
Matematikailag is magabiztosabb a konvergencia egy határig, ha ezt növeljük, 
valamint a GPU-RAM átviteli sávszélessége ugyan nagy, de nagy a konstans késletetés, 
ami abból adódik, hogy a videókártya vezérlőszofver nem azonnal hajtja végre az adatmozgatást,
hanem csak ha elég sok összegyűlt, vagy némi idő eltelt, ezzel javítva az teljesítményt teljes 
kihasználtság esetén. Egy eposz feldolgozása akár tízszer lassabb is lehet, ha a példákat
egyesével tápláljuk be.




\textit{Megjegyzés}: Talán hiba, de mindenesetre létező jelenség a Tensorflow csomagban, ha GPU implementációt használunk a program kezdetekor megpróbálja a lehető legtöbb 
munkamemóriát lefoglalni magának, ami nem mindig sikerül, 
ezért előfordulhat hogy hibával elszáll a program. Erre jó workaroundnak bizonyult, hogy
korlátoztuk, hogy maximum mennyit foglalhat le. Erre szolgál a következő utasítás a kódban:
\begin{lstlisting}
	config.gpu_options.per_process_gpu_memory_fraction = 0.7
\end{lstlisting}


Felmerül a kérdés, hogy miért nem mindent a GPU-n tárolunk, ezzel megspórolva az adatmozgatást.
Sajnos körülbelül 1000 tanító képünk volt, $ 1600 \times 1600 $ felbontásban. 
Tömörítetlenül ez nem fért el a memóriában. Ezt később ugyan lecsökkentettük
$ 1000 \times 1000 $-re, így elméletben már elfért volna, de ez nem került implementálásra,
mert hosszú távon több kép esetén úgyis probléma lenne.



Találkozhatunk egy figyelmeztető üzenettel, ha elfogy a memória, ami bár nem 
okoz elszállást, de ilyenkor lassabban fut a program. Ezért érdemes úgy megválasztani
a paramétereket, hogy ez ne következzen be.


Ezek miatt a kötegeket dinamikusan töltjük be a lemezről, és adjuk át feldolgozásra.
Egy köteg mérete jelenleg 16, de ez erősebb vagy gyengébb hardver függvényében 
növelhető vagy csökkenthető. A jelenlegi modellméret és képfelbontás mellett, ez 
körülbelül a határ a tesztgépen. Ez abból adódik, hogy a Keras felépíti memóriában 
a teljes futószalagot (\textit{pipeline}), ami csak az első rétegben
$ 3 \times 1000 \times 1000 \times \times 256 $ bájt memóriát foglalna.
Ezt kicsivel csökkentettük azzal, hogy a képeknek csak az egyik, jobb felső,
$ 256 \times 256 $ pixeles sarkát használtuk fel. A kísérletek szerint ez nem okozott
jelentős minőségromlást, de természetesen egy éles, ipari környezetben ez nem lenne
elhanyagolható.


\paragraph{Képformátum}
Az \texttt{opencv} könyvtárat használjuk a képek betöltésére.
A bemeneti képeink fájlformátuma bármi olyan lehet, amit az \texttt{opencv} támogat.
Mi \texttt{PNG}-t használunk a veszteségmentes tömörítés miatt, de nem elképzelhetetlen
a \texttt{TIFF} sem.


A \texttt{cv2.imread()} egy 8 bites egészeket
tartalmazó \texttt{numpy} tömböt ad vissza. Viszont mivel mi lebegőpontos számokkal fogunk számolni,
0 és 1 közé transzformáljuk a bemenetet. Ez a modell szempontjából irreleváns lenne,
de ha az ember ilyen képeket szeretne hibakeresés céljából megjeleníteni, akkor a
könyvtári megjelenítő függvények konvencionálisan ilyen értékeket várnak.


A képek reprezentációja könyvtáraktól függően különbözhet továbbá az egyes dimenziók 
sorrendjében, ezért fontos hogy konzisztensek legyünk. Mi az \texttt{opencv}-hez
igazodtunk, ahol a tömb \textit{alakja (shape)} : 
$ \mathbb{R}^{height \times width \times channels } $. 
Tehát egy pixel három színe három, fizikailag egymás mellett lévő érték,
míg más reprezentációkban előfordul, hogy a csatornák vannak elől, azaz három különálló
szürkeárnyalatos képünk van.


\paragraph{Adathalmaz}

Körülbelül 1000 kép állt rendelkezésünkre tanításkor, ezek 80\%-a volt
eredeti, a maradék 20\% hamisítvány. 


Emiatt szükséges volt a mintát kiegyensúlyozni, tehát gondoskodni arról,
hogy tanításnál mindkét csoportból azonos valószínűséggel lásson mintát 
a modell. Az egyik, kevésbé elegáns módszer az volt, hogy a kisebb (negatív) 
halmazból addig szúrtunk be véletlenszerűen a tanító minták közé, 
amíg egyenlő nem lett a két halmaz elemszáma.
Ennél szofisztikáltabb megoldás, a \texttt{Keras} \texttt{class\_weights} paraméterét
használni, amellyel megadhatjuk, hogy egy-egy osztályt milyen mértékben vegyen 
figyelembe a tanításnál. Az \texttt{sklearn} csomag biztosít egy függvényt,
\texttt{sklearn.utils.compute\_class\_weight} néven, vagy kézzel könnyen kiszámolhatjuk 
magunknak:

$ w_k' =  \dfrac{n}{ \sumn{i} \chi\{y_i = k\}}  $

$ w_k =  \dfrac{w_k'}{\sumn{i} w_i'} $


A képek különböző telefonokkal készültek, némely állványról, a többi pedig kézből.
Ez nagyban tudja befolyásolni a képminőséget.


Tanítás előtt képezünk egy tanító, egy validációs és egy teszt halmazt, ahol 
$ 70:15:15 $ az elemek számának aránya. Ezután, hacsak nem volt változás az adathalmazban,
ezt használtuk a végsőkig.



\paragraph{Adat augmentálás}

Fent írtunk arról, hogy ha relatív kevés tanító adatunk van, hogyan is tudunk
ezekből újakat generálni. Képfeldolgozással foglalkozó témákban ez azt jelenti,
hogy valamilyen affin transzformációt hajtunk végre a képen, ezáltal növelve a 
generalizálást. Viszont mivel mi a kezdő lépésben normalizáljuk a képünket azzal,
hogy a négy célzópontot egy négyzetté transzformáljuk, elveszítjük ennek a módszernek
a jelentőségét.


Jó kutatási terület lehet, hogy ezt hogyan lehet feladatspecifikusan és valósághűen 
mégis véghez vinni, például a fényviszonyok változásának szimulálásával.

\paragraph{Dropout} Továbbra is működik véletlenszerű kiejtés módszere,
azaz tanítás során két réteg között az áramló adat véletlenszerűen elveszik
egy előre megadott valószínűségi változó szerint. Mi $ p=0.5 $ egyenletes 
eloszlást használtunk. Ez a módszer jó mind konvolúciós, mind a sűrű rétegekre.



\paragraph{Optimalizáló}

Ahogy az előző fejezetben írtunk a tanítás problémáját tulajdonképpen visszavezettük
egy numerikus optimalizációs feladatra. Erre több módszer létezik, de általában a 
Gradiens Módszeren alapulnak. Mi az Adaptív Momemtum Becslés 
(\textit{Adaptive Moment Estimation, Adam~\cite{adam} }) módszert használtuk.

\noindent
Az algoritmus röviden:

$ m_w^{t+1} = \beta_1 \cdot m_w^{t} + (1-\beta_1) \triangledown_w J(w_t) $

$ v_w^{t+1} = \beta_2 \cdot v_w^{t} + (1-\beta_1) (\triangledown_w J(w_t))^2 $

$ \hat{m}_w = \dfrac{m_w^{t+1}}{1 - \beta_1} $

$ \hat{v}_w = \dfrac{v_w^{t+1}}{1 - \beta_2} $

$ w^{t+1} = w^{t} - \gamma \dfrac{\hat{m}_w}{\hat{v}_w + \epsilon}   $

\noindent
Ahol $ \beta_{1,2} $ a felejtési együtthatók, $ \gamma $ a tanulási együttható,
$ w $ az optimalizálandó paraméter, és $ J $ a költségfüggvény.

\noindent
\texttt{Kerasban} az alapbeállítások: 
$ \beta_1=0.9, \beta_2=0.999, \epsilon=1e-08, \gamma=0.001 $

%Keras: lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0.


\subsubsection{Modell készítés}

A paraméterek függvényében ellenőrizzük, hogy elérhető-e előző munkamenet.
Ha igen, akkor megpróbáljuk betölteni. Az elmentett modell kétféle lehet:

\begin{itemize}
	\item 
	Csak súlyok. Csak akkor van értelme, ha már végleges verziónk van.
	\item 
	"Teljes modell", ahol a súlyok mellett a háló szerkezete, és az optimalizáló állapota
	is elmentésre kerül.
\end{itemize}



Ezután két részre bontottuk a feladatot, amelyek egymástól függetlenül futtathatók.
Az első a háló tanítása (akár meglévő finomítása), a második modell használata 
és statisztikai értékelése.


\subsubsection{Első fázis}

Ha elkészült a modell, akkor készen állunk a tanításra. Ha teljes modellt töltöttünk be,
akkor pont onnan folytatjuk, ahol abbahagytuk, csak súlyok esetén jelentősen visszaesünk 
eleinte, modell nélkül pedig "nulláról"(véletlenszerűen inicializált állapotból) kezdünk.

Az effektív tanítás \texttt{keras.models.Sequential.fit\_generator()} metódus segítségével 
történik.

Ennek a paramétereiként meg kell adnunk a tanító és a validációs halmazokat \texttt{python} 
generátorok formájában. Ezek olyan \texttt{numpy} tömböt adnak vissza, amely megfelel 
egy kötegnek, és egy eleme egy kép. A \texttt{steps\_per\_epoch} paraméterrel azt adjuk
meg, hogy egy \textit{eposz} hány köteg. A \texttt{callbacks} paraméterrel függvényeket
adunk a modellnek, amelyek bizonyos események bekövetkeztével meghívódnak. Tipikusan a
\texttt{on\_epoch\_end} callbacket használtuk.

\noindent
A következőket definiáltuk:

\paragraph{Korai megállás} (\textit{Early stopping})

Nem a \texttt{Keras} beépített függvényét használtuk, hanem sajátot írtunk a
nagyobb szabadság miatt. A feladata, hogy ha a validációs hiba már nem csökken akkor 
szakítsa meg a tanítást. Viszont azt tapasztaltuk, hogy előfordul, hogy néha
egy-egy eposz erejéig a hiba nő, ámde a következőben újra stabilan csökken.
Ezért csak akkor állunk meg ha a validációs hiba három egymást követő eposzban
nem csökkent.

\texttt{Kerasban} a validációs hibát a \texttt{on\_epoch\_end(self, epoch, logs=\{\})} 
callback függvényben a \texttt{logs.get(self.monitor)} utasítással kapjuk meg.

Megadhatunk explicit legtöbb eposz-számot is, és validációs hibahatárt, ami alá ha
elérünk akkor elvégezettnek tekintjük a feladatot, de ezt a gyakorlatban nem használtuk.
Addig tanítottuk, ameddig csak lehetett.

\paragraph{Ellenőrzőpont}

Mivel a tanítás hosszú folyamat, eközben akár össze is omolhat a rendszer, vagy
a modell elkezdhet egy idő után \textit{túltanulni}. Többek között ezek miatt fontos,
hogy rendszeres időközönként elmentsük a jelenlegi állapotot. Ehhez egy 
\textit{Checkpoint~Callbacket} implementáltunk, amely a jelenlegi verzióban minden ötödik
eposz után a lemezre menti a modellt, ellátva egy időbélyegzővel.



\subsubsection{Második fázis}
\label{sec:masodik.fazis}

A második fázisban egy már betanított modellt használunk. Ekkor már tudunk predikciókat 
végezni, és ezáltal hatékonyságot mérni. A bináris osztályozó tulajdonsága, hogy bár
a formátum különbözhet, az eredmény végső soron egy 0 és 1 közötti szám. Meg kell egy határoznunk egy-egy diszjunkt intervallumot az osztályokhoz, amelyikbe beleesik azt mondjuk
a klasszifikáció eredményének. Ha szükséges felvehetünk egy harmadik intervallumot is 
az előző kettő közé, amelyben nem vagyunk biztosak.


Ezeket az intervallumokat nem tudjuk triviálisan meghatározni, ugyanis függnek az 
elvárt maximális első- és másodfajú hibarátától. Tekintsük a kétintervallumos esetet!

Ahogy azt már korábban említettük, a kétféle hibaráta egymás rovására javítható a 
vágópont különböző megválasztásával. Az ezek közti összefüggést jól mutatja a 
ROC-görbe, ahol a fals pozitív ráta függvényében láthatjuk a tényleges
pozitív rátát, ahol $ tp = 1 - fn $. 
(\ref{fig:roc.pelda}. ábra)


\begin{figure}[htbp]
	\centering
	\includesvg[scale=0.5]{img/rocexample}
	\caption{ROC-görbe}
	\label{fig:roc.pelda}
\end{figure}


TODO lehetne egy dupla hisztogramot iderakni

Ha az adathalmaz nem tökéletesen szeparálható ( a görbe alatti terület nem 1), akkor
nem tudunk univerzálisan jó vágópontot mondani, viszont azt igen hogy egy adott ponthoz 
mekkora fals és tényleges ráta tartozik. Ezek alapján el kell döntenünk, hogy az 
első- vagy a másodfajú hiba a kritikusabb, erre meghatároznunk egy maximum hibarátát,
például 1\%, és ez alapján megadni a küszöböt.


Amennyiben három intervallumot használunk mindkét hibát kontrollálni tudjuk, cserébe a 
bizonytalanságért. Viszont ez az állapot javítható újbóli mintavételezéssel, azaz 
ez esetben új kép készítésével, vagy esetleg egy másik módszer ajánlásával.











\noindent\rule{15cm}{0.4pt}
roc görbe, vágás, dunno,


*memória warning
*float vs int
batchek száma, early stopping, checkpoint

*tensorflow gpu 
*on the fly loading - nem fér be 1000 kép
*adatB méret
*honnan vannak, különböző telefonok
hiányosságok
a rossz képek előszűrve vannak a pontkeresés miatt de ez még kutatásra szorul

*augmentálás fail, dropout

megszopatta az offset nyomat
*mekkorát vágtunk ki mert elfogyott a memória
*egyentranszformáció
*mennyi képünk volt
súly vs teljes modell

3stage - külön értékelhető / javitható stb
statisztikai mérés / külön modul

talán megmutatni hogy hogy meg a konv net tanítás?
betöltés vagy ujragenerálás
logolásról lehetne pár szó






\subsection{Képelemzés Autoencoderrel}


Egy másik megközelítés volt a konvolúciós hálók alkalmazására, hogy autoencoder modellt 
építünk, majd a rekonstrukciós hiba alapján döntünk.

Egy autoencoder feladata hogy a kapott inputot úgy tömörítse a rejtett rétegeket
használva, hogy a veszteség a lehető legkisebb legyen.

Az modell tanításához kiválogattuk az eredeti képeket, és csak azokon tanítottunk.
Azt vártuk, hogy jelentős különbséget fogunk tapasztalni az eredeti és a hamis 
kimenetekben. Erről részletesen az eredmények fejezetben.


\subsubsection{Modell}
\noindent
\textbf{Keras segítségével a következő modellt építettük:}


\lstset{language=Python}
\begin{lstlisting}  

	model = Sequential()
	
	kernel_sizes = [7, 7, 7]
	kernel_dims = list(map(lambda x: (x,x), kernel_sizes))
	iterator = iter(kernel_dims)
	reverse_iterator = reversed(kernel_dims)
	
	padding = "same"
	
	padding_size = sum(kernel_sizes)*2
	
	model.add(ZeroPadding2D(padding=(padding_size, padding_size), input_shape=(None, None, 3)))
	model.add(Conv2D(64, next(iterator), padding=padding))
	model.add(Activation('relu'))
	model.add(MaxPooling2D(pool_size=(2, 2)))
	
	model.add(Conv2D(128, next(iterator), padding=padding))
	model.add(Activation('relu'))
	model.add(MaxPooling2D(pool_size=(2, 2)))
	
	model.add(Conv2D(256, next(iterator), padding=padding))
	model.add(Activation('relu'))
	
	# Visszaalakitas
	
	model.add(Conv2DTranspose(128, next(reverse_iterator), padding=padding))
	model.add(Activation('relu'))
	model.add(UpSampling2D(size=(2, 2)))
	
	model.add(Conv2DTranspose(64, next(reverse_iterator), padding=padding))
	model.add(Activation('relu'))
	model.add(UpSampling2D(size=(2, 2)))
	
	model.add(Conv2DTranspose(3, next(reverse_iterator), padding=padding))
	model.add(Cropping2D(cropping=(padding_size, padding_size)))
	
	model.compile(
		loss='mean_squared_error',
		optimizer='adam', 
		metrics=['accuracy']) 
) 

\end{lstlisting}


Az előző fejezet konvolúciós hálójához hasonlóan Konvolúció-Relu-MaxPooling hármasokat
fűztünk egymás után. Úgy találtuk hogy az általánosítás $ 7 \time 7 $-es kernelméret 
mellett volt. Kisebb túltanult, jelentősen nagyobb ($ 11  $és felette) már nem volt 
képes értékelhető eredményt adni.

A háló második fel az első tükrözve, figyelve arra, hogy a végső dimenzió pont akkora 
legyen, mint a bemenet. A MaxPoolingok párja egy-egy UpSampling réteg, amely az adott
pixelt egy $ 2 \times 2 $-es ablakban megtöbbszörözi.

Költségfüggvények átlagos hiba-négyzetet (\textit{MSE}) használunk, hiszen arra vagyunk 
kíváncsiak, hogy fizikailag mennyire voltunk közel az eredeti képhez.


Érdekessége a hálónak, hogy \textit{hely-invariáns}, azaz a kép koordinátáitól nem függ az adott
adategységhez tartozó kimenet, kizárólag a szomszédaitól és a megtanult szűrőktől.
Ezt ki is használjuk: az \texttt{ input\_shape=(None, None, 3)} utasítással annyit
specifikálunk csak, hogy az input 3 színcsatornával kell rendelkezzen, de tetszőleges
a szélesség és a magasság. Ekkor bár az kötött, hogy tanításkor a példák egyforma 
dimenziójúak legyenek a hatékonyság miatt, de a méretük így is tetszőleges.


Megtehetjük tehát, hogy tanításnál sok kis kockát mutatunk a modellnek, viszont tesztelésnél
már az egész képet állítjuk vissza, az eredmény ugyanaz lesz. Ez magyarázható a konvolúció 
tulajdonságaival, erre alapul például jelfeldolgozásban az \textit{overlap-save} módszer.



\subsubsection{Osztályozás}

A háló kimenete az átlagos rekonstrukciós hiba. Az osztályozás ez alapján történik,
hasonlóan a \ref{sec:masodik.fazis} pontban leírtakhoz, azaz választunk egy küszöböt:
ha ez alatt van a hiba, akkor az eredetiség mellett döntünk, különben ellene.



\newpage
\section{Eredmények}
TODO

összehasonlítani a jurás eredménnyel

\newpage
\section{Konklúzió}

további feladatok:

például mobilra átültetni


\paragraph{TODO:}

lehetne majd pozicionálásra is megpróbálni


kis kikockázás

batch, eposz
dropout, normalizálás, balancing, augmentation
loss/accuracy - roc görbe "siker mérése"
test/val/train
early stopping
MERGED images??? dunno?



\newpage
\begin{thebibliography}{9}
	\bibitem{adam} 
	Diederik P. Kingma, Jimmy Ba:
	Adam: A Method for Stochastic Optimization
	arXiv:1412.6980v9 [cs.LG]
	
\end{thebibliography}




We did a pretty good\textsuperscript{\textit{job}}so far



